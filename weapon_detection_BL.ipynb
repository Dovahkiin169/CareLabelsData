{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weapon_detection_BL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sOcbTFEiPBKA",
        "pOfuwfPrPSMz",
        "A_tyvKnBP6qD",
        "t9C3L_r4Pi6m",
        "xMckMSJqFMyc",
        "8vAGvftxHu8K",
        "IuJcAPZFIfu7",
        "RPN8liiQc7Ue"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubUsE7qtMWfj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Inroduction**:\n",
        "\n",
        "\n",
        "Aiming to minimize police response time by detecting weapons in a live cctv camera. The main motivation of this project is due to the increasing number of school mass shootings in the U.S.\n",
        "\n",
        "\n",
        "### This notebook is a part of this [medium post](https://medium.com/@alaasinjab/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi0JMo0RNT2Y",
        "colab_type": "text"
      },
      "source": [
        "### This notebook was designed to be ran from top to bottom without the need to mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65t7YUhnzDCE",
        "colab_type": "text"
      },
      "source": [
        "## Weapon Detection Using Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWrRz3kXDksW",
        "colab_type": "text"
      },
      "source": [
        "Workspace structure\n",
        "\n",
        "```\n",
        "gun_detection/\n",
        "        ├─ data/\n",
        "        │    ├── images/\n",
        "        │    │      ├── armas (1).jpg\n",
        "        │    │      ├── armas (2).jpg\n",
        "        │    │      └── ...\n",
        "        │    ├── train_labels/\n",
        "        │    │      ├── armas (1).xml\n",
        "        │    │      ├── armas (2).xml\n",
        "        │    │      └── ...\n",
        "        │    ├── test_labels/\n",
        "        │    │      ├── armas (10).xml\n",
        "        │    │      ├── armas (20).xml\n",
        "        │    │      └── ...\n",
        "        │    ├── label_map.pbtxt\n",
        "        │    ├── test_labels.csv\n",
        "        │    ├── train_labels.csv\n",
        "        │    ├── test_labels.record\n",
        "        │    └── train_labels.record\n",
        "        └─ models/\n",
        "             ├─ research/\n",
        "             │      ├── fine_tuned_model/\n",
        "             │      │         ├── frozen_inference_graph.pb\n",
        "             │      │         └── ...\n",
        "             │      │         \n",
        "             │      ├── pretrained_model/\n",
        "             │      │         ├── frozen_inference_graph.pb\n",
        "             │      │         └── ...\n",
        "             │      │         \n",
        "             │      ├── object_detection/\n",
        "             │      │         ├── utils/\n",
        "             │      │         ├── samples/\n",
        "             │      │         │      ├── samples/ \n",
        "             │      │         │      │       ├── configs/             \n",
        "             │      │         │      │       │     ├── ssd_mobilenet_v2_coco.config\n",
        "             │      │         │      │       │     ├── rfcn_resnet101_pets.config\n",
        "             │      │         │      │       │     └── ...\n",
        "             │      │         │      │       └── ... \n",
        "             │      │         │      └── ...                                \n",
        "             │      │         ├── export_inference_graph.py\n",
        "             │      │         ├── model_main.py\n",
        "             │      │         └── ...\n",
        "             │      │         \n",
        "             │      ├── training/\n",
        "             │      │         ├── events.out.tfevents.xxxxx\n",
        "             │      │         └── ...               \n",
        "             │      └── ...\n",
        "             └── ...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlXJ2yIV8e7",
        "colab_type": "text"
      },
      "source": [
        "## Choosing a pre training model\n",
        "The model used for this project is `ssd_mobilenet_v2_coco`.\n",
        "Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        "\n",
        "Because the interestes of this project is to interfere on real time video, i am chosing a model that has a high inference speed `(ms)` with relativly high `mAP` on COCO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3_Ns54i3HgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b7c87771-817e-44d4-a181-ffef621d9699"
      },
      "source": [
        "\n",
        "%tensorflow_version 1.x # Select module of the tensorflow\n",
        "# Some models to train on\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "    }\n",
        "}\n",
        "\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "# I chose ssd_mobilenet_v2 for this project, you could choose any\n",
        "selected_model = 'ssd_mobilenet_v2'\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x # Select module of the tensorflow`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3Zm042QGJy",
        "colab_type": "text"
      },
      "source": [
        "## Installing Required Packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68StUELaQPS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "ccb59abc-eb71-4153-89a4-e195991910a3"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -qq pycocotools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144579 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERyocH9U-o2Y",
        "colab_type": "text"
      },
      "source": [
        "## General imports\n",
        "Other Imports will be done after downloading some packages later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEVLeKXh-s23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import cv2 \n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import io\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from PIL import Image\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "import shutil\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8QeHvX6gpmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19d1e014-63c0-496a-8734-5177873e5b9b"
      },
      "source": [
        "#we need tenorflow v 1.15.0, object detection API is removed from tf v 2.0+\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOcbTFEiPBKA",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Orgniazing Images and Annotations\n",
        "1. Downloading the images and annotations from the [source](https://sci2s.ugr.es/weapons-detection)  and unziping them\n",
        "2. Creating a directory `(data)` to save some data such as; images, annotation, csv, etc...\n",
        "3. Creating two directories; for the training and testing labels (not the images)\n",
        "4. Randomly splitting our labels into 80% training and 20% testing and moving the splits to their directories: `(train_labels)` & `(test_labels)` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QY-CyUQwyZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates a directory for the whole project\n",
        "!mkdir gun_detection"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHPQQmhm7RLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4d1eb3d-4d59-4ebc-aeaf-a2056d0b7d0b"
      },
      "source": [
        "cd gun_detection"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp62o3a07UbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7da234-350e-4dd6-d5ff-73d3d0bd176b"
      },
      "source": [
        "#Training images and annotations\n",
        "\n",
        "#Source: https://sci2s.ugr.es/weapons-detection\n",
        "\n",
        "\n",
        "#download the images zip\n",
        "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n",
        "\n",
        "#unzip the image file\n",
        "!unzip -q WeaponS.zip\n",
        "\n",
        "#download the annotations zip\n",
        "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n",
        "\n",
        "#unzip the annotations file\n",
        "!unzip -q WeaponS_bbox.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-22 04:03:14--  https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n",
            "Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n",
            "Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 250005059 (238M) [application/zip]\n",
            "Saving to: ‘WeaponS.zip’\n",
            "\n",
            "WeaponS.zip         100%[===================>] 238.42M  11.1MB/s    in 22s     \n",
            "\n",
            "2019-12-22 04:03:36 (11.1 MB/s) - ‘WeaponS.zip’ saved [250005059/250005059]\n",
            "\n",
            "--2019-12-22 04:03:40--  https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n",
            "Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n",
            "Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1420022 (1.4M) [application/zip]\n",
            "Saving to: ‘WeaponS_bbox.zip’\n",
            "\n",
            "WeaponS_bbox.zip    100%[===================>]   1.35M  5.58MB/s    in 0.2s    \n",
            "\n",
            "2019-12-22 04:03:40 (5.58 MB/s) - ‘WeaponS_bbox.zip’ saved [1420022/1420022]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0czMMeR8GxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a directory to store the training and testing data\n",
        "!mkdir data\n",
        "\n",
        "# folders for the training and testing data.\n",
        "!mkdir data/images data/train_labels data/test_labels\n",
        "\n",
        "\n",
        "# combining the images and annotation in the training folder:\n",
        "# moves the images to data folder\n",
        "#!mv WeaponS/* data/images\n",
        "\n",
        "# moves the annotations to data folder\n",
        "#!mv WeaponS_bbox/* data/train_labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv8pmB2D80M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deleting the zipped and unzipped folders \n",
        "!rm -rf WeaponS_bbox.zip  WeaponS.zip WeaponS/  WeaponS_bbox/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUl-XRwPvj4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n",
        "# Moves the first 600 labels to the testing dir: `test_labels`\n",
        "!ls data/train_labels/* | sort -R | head -600 | xargs -I{} mv {} data/test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmvDu-rUHz96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be616d03-d0dd-454c-c7d2-7c0e0cbdd466"
      },
      "source": [
        "# 2400 \"images\"(xml) for training\n",
        "ls -1 data/train_labels/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8y-1_t7wRJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334e9c64-6496-4a72-ccdd-bdf944900073"
      },
      "source": [
        "# 600 \"images\"(xml) for testing\n",
        "ls -1 data/test_labels/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI7Nq01lriOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/gun_detection/data/train_labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JxCdR-c8yGp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOfuwfPrPSMz",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Images and Labels\n",
        "1. Converting the annotations from xml files to two csv files for each `train_labels/` and `train_labels/`.\n",
        "2. Creating a pbtxt file that specifies the number of class (one class in this case)\n",
        "3. Checking if the annotations for each object are placed within the range of the image width and height."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBHBFpWyEIDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "32773b96-3e43-465e-bfe5-f5b530adc5ad"
      },
      "source": [
        "\n",
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "\n",
        "#converts the annotations/labels into one csv file for each training and testing labels\n",
        "#creats label_map.pbtxt file\n",
        "\n",
        "%cd /content/gun_detection/data\n",
        "\n",
        "\n",
        "# images extension\n",
        "images_extension = 'jpg'\n",
        "\n",
        "# takes the path of a directory that contains xml files and converts\n",
        "#  them to one csv file.\n",
        "\n",
        "# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n",
        "# note: if the xml file contains more than one box/label, it will create more than one row for the same image. each row contains the info for an individual box. \n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text + '.' + images_extension,\n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "# Creating the `label_map.pbtxt` file\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "#creats a pbtxt file the has the class names.\n",
        "for i, class_name in enumerate(classes):\n",
        "    # display_name is optional.\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: '{1}'\\n }}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/data\n",
            "Successfully converted train_labels xml to csv.\n",
            "Successfully converted test_labels xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtfjZcD-CCdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88e4f33b-02f7-42e2-9e8b-32c5253c7beb"
      },
      "source": [
        "#checking the pbtxt file\n",
        "!cat label_map.pbtxt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "    id: 1\n",
            "    name: 'bleaching_with_chlorine_allowed'\n",
            "    display_name: 'bleaching_with_chlorine_allowed'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 2\n",
            "    name: 'chlorine_and_non_chlorine_bleach'\n",
            "    display_name: 'chlorine_and_non_chlorine_bleach'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 3\n",
            "    name: 'do_not_bleach'\n",
            "    display_name: 'do_not_bleach'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 4\n",
            "    name: 'do_not_dry_clean'\n",
            "    display_name: 'do_not_dry_clean'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 5\n",
            "    name: 'do_not_iron'\n",
            "    display_name: 'do_not_iron'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 6\n",
            "    name: 'do_not_tumble_drying'\n",
            "    display_name: 'do_not_tumble_drying'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 7\n",
            "    name: 'do_not_wash'\n",
            "    display_name: 'do_not_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 8\n",
            "    name: 'do_not_wet_clean'\n",
            "    display_name: 'do_not_wet_clean'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 9\n",
            "    name: 'drip_dry_in_the_shade'\n",
            "    display_name: 'drip_dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 10\n",
            "    name: 'drip_dry'\n",
            "    display_name: 'drip_dry'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 11\n",
            "    name: 'dry_clean_any_solvent'\n",
            "    display_name: 'dry_clean_any_solvent'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 12\n",
            "    name: 'dry_clean_hydrocarbon_solvent_only_hcs'\n",
            "    display_name: 'dry_clean_hydrocarbon_solvent_only_hcs'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 13\n",
            "    name: 'dry_clean_tetrachloroethylene_pce_only'\n",
            "    display_name: 'dry_clean_tetrachloroethylene_pce_only'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 14\n",
            "    name: 'dry_flat_in_the_shade'\n",
            "    display_name: 'dry_flat_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 15\n",
            "    name: 'dry_flat'\n",
            "    display_name: 'dry_flat'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 16\n",
            "    name: 'dry_in_the_shade'\n",
            "    display_name: 'dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 17\n",
            "    name: 'drying_symbol'\n",
            "    display_name: 'drying_symbol'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 18\n",
            "    name: 'gentle_cleaning_with_hydrocarbon_solvents'\n",
            "    display_name: 'gentle_cleaning_with_hydrocarbon_solvents'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 19\n",
            "    name: 'gentle_cleaning_with_pce'\n",
            "    display_name: 'gentle_cleaning_with_pce'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 20\n",
            "    name: 'gentle_wet_cleaning'\n",
            "    display_name: 'gentle_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 21\n",
            "    name: 'hand_wash'\n",
            "    display_name: 'hand_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 22\n",
            "    name: 'ironing_at_high_temp'\n",
            "    display_name: 'ironing_at_high_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 23\n",
            "    name: 'ironing_at_low_temp'\n",
            "    display_name: 'ironing_at_low_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 24\n",
            "    name: 'ironing_at_med_temp'\n",
            "    display_name: 'ironing_at_med_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 25\n",
            "    name: 'ironing'\n",
            "    display_name: 'ironing'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 26\n",
            "    name: 'line_dry_in_the_shade'\n",
            "    display_name: 'line_dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 27\n",
            "    name: 'line_dry'\n",
            "    display_name: 'line_dry'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 28\n",
            "    name: 'no_steam'\n",
            "    display_name: 'no_steam'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 29\n",
            "    name: 'non_chlorine_bleach_when_needed'\n",
            "    display_name: 'non_chlorine_bleach_when_needed'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 30\n",
            "    name: 'professional_cleaning'\n",
            "    display_name: 'professional_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 31\n",
            "    name: 'professional_wet_cleaning'\n",
            "    display_name: 'professional_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 32\n",
            "    name: 'tumble_drying_low_temps'\n",
            "    display_name: 'tumble_drying_low_temps'\n",
            " }\n",
            " \n",
            "  item {\n",
            "    id: 33\n",
            "    name: 'tumble_drying_normal'\n",
            "    display_name: 'tumble_drying_normal'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 34\n",
            "    name: 'tumble_drying'\n",
            "    display_name: 'tumble_drying'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 35\n",
            "    name: 'very_gentle_cleaning_with_hydrocarbon_solvents'\n",
            "    display_name: 'very_gentle_cleaning_with_hydrocarbon_solvents'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 36\n",
            "    name: 'very_gentle_cleaning_with_pce'\n",
            "    display_name: 'very_gentle_cleaning_with_pce'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 37\n",
            "    name: 'very_gentle_wet_cleaning'\n",
            "    display_name: 'very_gentle_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 38\n",
            "    name: 'wash_at_or_below_30_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_30_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 39\n",
            "    name: 'wash_at_or_below_30_very_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_30_very_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 40\n",
            "    name: 'wash_at_or_below_30'\n",
            "    display_name: 'wash_at_or_below_30'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 41\n",
            "    name: 'wash_at_or_below_40_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_40_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 42\n",
            "    name: 'wash_at_or_below_40_very_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_40_very_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 43\n",
            "    name: 'wash_at_or_below_40'\n",
            "    display_name: 'wash_at_or_below_40'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 44\n",
            "    name: 'wash_at_or_below_50_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_50_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 45\n",
            "    name: 'wash_at_or_below_50'\n",
            "    display_name: 'wash_at_or_below_50'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 46\n",
            "    name: 'wash_at_or_below_60_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_60_mild_fine_wash'\n",
            " }\n",
            "\n",
            "   item {\n",
            "    id: 47\n",
            "    name: 'wash_at_or_below_60'\n",
            "    display_name: 'wash_at_or_below_60'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 48\n",
            "    name: 'wash_at_or_below_70'\n",
            "    display_name: 'wash_at_or_below_70'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 49\n",
            "    name: 'wash_at_or_below_90'\n",
            "    display_name: 'wash_at_or_below_90'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 50\n",
            "    name: 'washing_symbol'\n",
            "    display_name: 'washing_symbol'\n",
            " }"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP8gohagKFXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0c6d5f3c-e2b8-433d-97f7-cb74691c4625"
      },
      "source": [
        "# they are there!\n",
        "!ls -l"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 36\n",
            "drwxr-xr-x 2 root root  4096 Sep 10 16:57 images\n",
            "-rw-r--r-- 1 root root  5092 Sep 10 16:59 label_map.pbtxt\n",
            "drwxr-xr-x 3 root root  4096 Sep 10 16:59 test_labels\n",
            "-rw-r--r-- 1 root root   417 Sep 10 16:59 test_labels.csv\n",
            "drwxr-xr-x 3 root root  4096 Sep 10 16:59 train_labels\n",
            "-rw-r--r-- 1 root root 12286 Sep 10 16:59 train_labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4p7J6mFLLZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "c4e891a8-1a2d-4832-bf84-09b1e057d5c9"
      },
      "source": [
        "#checks if the images box position is placed within the image.\n",
        "\n",
        "#note: while this doesn't checks if the boxes/annotatoins are correctly\n",
        "# placed around the object, Tensorflow will through an error if this occured.\n",
        "%cd /content/gun_detection/data\n",
        "# path to images\n",
        "images_path = 'images'\n",
        "\n",
        "#loops over both train_labels and test_labels csv files to do the check\n",
        "# returns the image name where an error is found \n",
        "# return the incorrect attributes; xmin, ymin, xmax, ymax.\n",
        "for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n",
        "  with open(CSV_FILE, 'r') as fid:  \n",
        "      print('[*] Checking file:', CSV_FILE) \n",
        "      file = csv.reader(fid, delimiter=',')\n",
        "      first = True \n",
        "      cnt = 0\n",
        "      error_cnt = 0\n",
        "      error = False\n",
        "      for row in file:\n",
        "          if error == True:\n",
        "              error_cnt += 1\n",
        "              error = False         \n",
        "          if first == True:\n",
        "              first = False\n",
        "              continue     \n",
        "          cnt += 1      \n",
        "          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n",
        "          path = os.path.join(images_path, name)\n",
        "          img = cv2.imread(path)         \n",
        "          if type(img) == type(None):\n",
        "              error = True\n",
        "              print('Could not read image', img)\n",
        "              continue     \n",
        "          org_height, org_width = img.shape[:2]     \n",
        "          if org_width != width:\n",
        "              error = True\n",
        "              print('Width mismatch for image: ', name, width, '!=', org_width)     \n",
        "          if org_height != height:\n",
        "              error = True\n",
        "              print('Height mismatch for image: ', name, height, '!=', org_height) \n",
        "          if xmin > org_width:\n",
        "              error = True\n",
        "              print('XMIN > org_width for file', name)  \n",
        "          if xmax > org_width:\n",
        "              error = True\n",
        "              print('XMAX > org_width for file', name)\n",
        "          if ymin > org_height:\n",
        "              error = True\n",
        "              print('YMIN > org_height for file', name)\n",
        "          if ymax > org_height:\n",
        "              error = True\n",
        "              print('YMAX > org_height for file', name)\n",
        "          if error == True:\n",
        "              print('Error for file: %s' % name)\n",
        "              print()\n",
        "      print()\n",
        "      print('Checked %d files and realized %d errors' % (cnt, error_cnt))\n",
        "      print(\"-----\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/data\n",
            "[*] Checking file: train_labels.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-e167342b9392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[*] Checking file:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSV_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'reader'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD5luKTsMx7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we have only one image with incorrect box position, we could just remove it \n",
        "#removing the image \n",
        "rm images/'armas (2815).jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze4z9bW3ZjhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing the entry for it in the csv for that image as well\n",
        "\n",
        "#because we did a random split for the data, we dont know if it ended up being in training or testing\n",
        "# we will remove the image from both.\n",
        "\n",
        "#training\n",
        "#reading the training csv\n",
        "df = pd.read_csv('/content/gun_detection/data/train_labels.csv')\n",
        "# removing armas (2815).jpg\n",
        "df = df[df['filename'] != 'armas (2815).jpg']\n",
        "#reseting the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#saving the df\n",
        "df.to_csv('/content/gun_detection/data/train_labels.csv')\n",
        "\n",
        "\n",
        "#testing\n",
        "#reading the testing csv\n",
        "df = pd.read_csv('/content/gun_detection/data/test_labels.csv')\n",
        "# removing armas (2815).jpg\n",
        "df = df[df['filename'] != 'armas (2815).jpg']\n",
        "#reseting the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#saving the df\n",
        "df.to_csv('/content/gun_detection/data/test_labels.csv')\n",
        "\n",
        "# Just for the memory\n",
        "df = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_tyvKnBP6qD",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Preparing Tensorflow model\n",
        "1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interseted in. \n",
        "2. Compiling the protos and adding folders to the os environment.\n",
        "3. Testing the model builder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIxz1GqJQA3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18fce249-910c-462f-9ebc-e406cf61d50a"
      },
      "source": [
        "# Downlaods Tenorflow\n",
        "%cd /content/gun_detection/\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjcAhsxRQ5N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c79f9871-72ea-4136-af87-ea1cd17684ff"
      },
      "source": [
        "%cd /content/gun_detection/models/research\n",
        "#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
        "os.environ['PYTHONPATH'] += ':/content/gun_detection/models/research/:/content/gun_detection/models/research/slim/'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMNsrwTSJi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a76957d9-8d98-4f21-aac4-2cce0a0c8fbe"
      },
      "source": [
        "# testing the model builder\n",
        "!pip3 install tf_slim\n",
        "!python3 object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9C3L_r4Pi6m",
        "colab_type": "text"
      },
      "source": [
        "## Generating Tf record\n",
        "- Generating two TFRecords files for the training and testing CSVs.\n",
        "- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage. Instead of loading the full data into memory, Tenorflow breaks the data into batches using these TFRecords automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK2unk-9LB_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "b516d866-f959-48e9-f304-4528050a4ca0"
      },
      "source": [
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "\n",
        "# converts the csv files for training and testing data to two TFRecords files.\n",
        "# places the output in the same directory as the input\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "%cd /content/gun_detection/models/\n",
        "\n",
        "DATA_BASE_PATH = '/content/gun_detection/data/'\n",
        "image_dir = '/content/gun_detection/data/images'\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "\t\tif row_label == 'bleaching_with_chlorine_allowed':\n",
        "\t\t\t\treturn 1\n",
        "\t\telif row_label == 'chlorine_and_non_chlorine_bleach':\n",
        "\t\t\t\treturn 2\n",
        "\t\telif row_label == 'do_not_bleach':\n",
        "\t\t\t\treturn 3\n",
        "\t\telif row_label == 'do_not_dry_clean':\n",
        "\t\t\t\treturn 4\n",
        "\t\telif row_label == 'do_not_iron':\n",
        "\t\t\t\treturn 5\n",
        "\t\telif row_label == 'do_not_tumble_drying':\n",
        "\t\t\t\treturn 6\n",
        "\t\telif row_label == 'do_not_wash':\n",
        "\t\t\t\treturn 7\n",
        "\t\telif row_label == 'do_not_wet_clean':\n",
        "\t\t\t\treturn 8\n",
        "\t\telif row_label == 'drip_dry_in_the_shade':\n",
        "\t\t\t\treturn 9\n",
        "\t\telif row_label == 'drip_dry':\n",
        "\t\t\t\treturn 10\n",
        "\t\telif row_label == 'dry_clean_any_solvent':\n",
        "\t\t\t\treturn 11\n",
        "\t\telif row_label == 'dry_clean_hydrocarbon_solvent_only_hcs':\n",
        "\t\t\t\treturn 12\n",
        "\t\telif row_label == 'dry_clean_tetrachloroethylene_pce_only':\n",
        "\t\t\t\treturn 13\n",
        "\t\telif row_label == 'dry_flat_in_the_shade':\n",
        "\t\t\t\treturn 14\n",
        "\t\telif row_label == 'dry_flat':\n",
        "\t\t\t\treturn 15\n",
        "\t\telif row_label == 'dry_in_the_shade':\n",
        "\t\t\t\treturn 16\n",
        "\t\telif row_label == 'drying_symbol':\n",
        "\t\t\t\treturn 17\n",
        "\t\telif row_label == 'gentle_cleaning_with_hydrocarbon_solvents':\n",
        "\t\t\t\treturn 18\n",
        "\t\telif row_label == 'gentle_cleaning_with_pce':\n",
        "\t\t\t\treturn 19\n",
        "\t\telif row_label == 'gentle_wet_cleaning':\n",
        "\t\t\t\treturn 20\n",
        "\t\telif row_label == 'hand_wash':\n",
        "\t\t\t\treturn 21\n",
        "\t\telif row_label == 'ironing_at_high_temp':\n",
        "\t\t\t\treturn 22\n",
        "\t\telif row_label == 'ironing_at_low_temp':\n",
        "\t\t\t\treturn 23\n",
        "\t\telif row_label == 'ironing_at_med_temp':\n",
        "\t\t\t\treturn 24\n",
        "\t\telif row_label == 'ironing':\n",
        "\t\t\t\treturn 25\n",
        "\t\telif row_label == 'line_dry_in_the_shade':\n",
        "\t\t\t\treturn 26\n",
        "\t\telif row_label == 'line_dry':\n",
        "\t\t\t\treturn 27\n",
        "\t\telif row_label == 'no_steam':\n",
        "\t\t\t\treturn 28\n",
        "\t\telif row_label == 'non_chlorine_bleach_when_needed':\n",
        "\t\t\t\treturn 29\n",
        "\t\telif row_label == 'professional_cleaning':\n",
        "\t\t\t\treturn 30\n",
        "\t\telif row_label == 'professional_wet_cleaning':\n",
        "\t\t\t\treturn 31\n",
        "\t\telif row_label == 'tumble_drying_low_temps':\n",
        "\t\t\t\treturn 32\n",
        "\t\telif row_label == 'tumble_drying_normal':\n",
        "\t\t\t\treturn 33\n",
        "\t\telif row_label == 'tumble_drying':\n",
        "\t\t\t\treturn 34\n",
        "\t\telif row_label == 'very_gentle_cleaning_with_hydrocarbon_solvents':\n",
        "\t\t\t\treturn 35\n",
        "\t\telif row_label == 'very_gentle_cleaning_with_pce':\n",
        "\t\t\t\treturn 36\n",
        "\t\telif row_label == 'very_gentle_wet_cleaning':\n",
        "\t\t\t\treturn 37\n",
        "\t\telif row_label == 'wash_at_or_below_30_mild_fine_wash':\n",
        "\t\t\t\treturn 38\n",
        "\t\telif row_label == 'wash_at_or_below_30_very_mild_fine_wash':\n",
        "\t\t\t\treturn 39\n",
        "\t\telif row_label == 'wash_at_or_below_30':\n",
        "\t\t\t\treturn 40\n",
        "\t\telif row_label == 'wash_at_or_below_40_mild_fine_wash':\n",
        "\t\t\t\treturn 41\n",
        "\t\telif row_label == 'wash_at_or_below_40_very_mild_fine_wash':\n",
        "\t\t\t\treturn 42\n",
        "\t\telif row_label == 'wash_at_or_below_40':\n",
        "\t\t\t\treturn 43\n",
        "\t\telif row_label == 'wash_at_or_below_50_mild_fine_wash':\n",
        "\t\t\t\treturn 44\n",
        "\t\telif row_label == 'wash_at_or_below_50':\n",
        "\t\t\t\treturn 45\n",
        "\t\telif row_label == 'wash_at_or_below_60_mild_fine_wash':\n",
        "\t\t\t\treturn 46\n",
        "\t\telif row_label == 'wash_at_or_below_60':\n",
        "\t\t\t\treturn 47\n",
        "\t\telif row_label == 'wash_at_or_below_70':\n",
        "\t\t\t\treturn 48\n",
        "\t\telif row_label == 'wash_at_or_below_90':\n",
        "\t\t\t\treturn 49\n",
        "\t\telif row_label == 'washing_symbol':\n",
        "\t\t\t\treturn 50\t\t\t\n",
        "\t\telse:\n",
        "\t\t\t\t0\n",
        "\n",
        "def split(df, group):\n",
        "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
        "\t\tgb = df.groupby(group)\n",
        "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(os.path.splitext(group.filename)[0])), 'rb') as fid:\n",
        "\t\t\t\tencoded_jpg = fid.read()\n",
        "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\t\timage = Image.open(encoded_jpg_io)\n",
        "\t\twidth, height = image.size\n",
        "\n",
        "\t\tfilename = group.filename.encode('utf8')\n",
        "\t\timage_format = b'jpg'\n",
        "\t\txmins = []\n",
        "\t\txmaxs = []\n",
        "\t\tymins = []\n",
        "\t\tymaxs = []\n",
        "\t\tclasses_text = []\n",
        "\t\tclasses = []\n",
        "\n",
        "\t\tfor index, row in group.object.iterrows():\n",
        "\t\t\t\txmins.append(row['xmin'] / width)\n",
        "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
        "\t\t\t\tymins.append(row['ymin'] / height)\n",
        "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
        "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
        "\n",
        "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t\t\t'image/filename': dataset_util.bytes_feature(os.path.splitext(filename)[0]),\n",
        "\t\t\t\t'image/source_id': dataset_util.bytes_feature(os.path.splitext(filename)[0]),\n",
        "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
        "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t\t}))\n",
        "\t\tprint(filename)\n",
        "\t\treturn tf_example\n",
        "\n",
        "for csv in ['train_labels', 'test_labels']:\n",
        "  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n",
        "  path = os.path.join(image_dir)\n",
        "  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "      tf_example = create_tf_example(group, path)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "    \n",
        "  writer.close()\n",
        "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
        "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models\n",
            "b'2020-09-07 19.05.53.jpg.jpg'\n",
            "b'2020-09-07 19.06.00.jpg.jpg'\n",
            "b'2020-09-07 19.06.05.jpg.jpg'\n",
            "b'2020-09-07 19.06.08.jpg.jpg'\n",
            "b'2020-09-07 19.06.16.jpg.jpg'\n",
            "b'2020-09-07 19.06.23.jpg.jpg'\n",
            "b'2020-09-07 19.06.26.jpg.jpg'\n",
            "b'2020-09-07 19.06.30.jpg.jpg'\n",
            "b'2020-09-07 19.06.34.jpg.jpg'\n",
            "b'2020-09-07 19.06.37.jpg.jpg'\n",
            "b'2020-09-07 19.06.40.jpg.jpg'\n",
            "b'2020-09-07 19.06.44.jpg.jpg'\n",
            "b'2020-09-07 19.06.47.jpg.jpg'\n",
            "b'2020-09-07 19.06.50.jpg.jpg'\n",
            "b'2020-09-07 19.06.54.jpg.jpg'\n",
            "b'2020-09-07 19.06.57.jpg.jpg'\n",
            "b'2020-09-07 19.07.00.jpg.jpg'\n",
            "b'2020-09-07 19.07.04.jpg.jpg'\n",
            "b'2020-09-07 19.07.08.jpg.jpg'\n",
            "b'2020-09-07 19.07.14.jpg.jpg'\n",
            "b'2020-09-07 19.07.17.jpg.jpg'\n",
            "b'2020-09-07 19.07.20.jpg.jpg'\n",
            "b'2020-09-07 19.07.23.jpg.jpg'\n",
            "b'2020-09-07 19.07.26.jpg.jpg'\n",
            "b'2020-09-07 19.07.29.jpg.jpg'\n",
            "b'2020-09-07 19.07.35.jpg.jpg'\n",
            "b'2020-09-07 19.07.39.jpg.jpg'\n",
            "b'2020-09-07 19.07.42.jpg.jpg'\n",
            "b'2020-09-07 19.07.45.jpg.jpg'\n",
            "b'2020-09-07 19.07.48.jpg.jpg'\n",
            "Successfully created the TFRecords: /content/gun_detection/data/train_labels.record\n",
            "b'2020-09-07 19.06.19.jpg.jpg'\n",
            "Successfully created the TFRecords: /content/gun_detection/data/test_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1zRJducWs-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6eafc95d-cfa9-4c80-a068-9d975d26c565"
      },
      "source": [
        "# TFRecords are created\n",
        "!ls -lX /content/gun_detection/data/"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4000\n",
            "drwxr-xr-x 2 root root    4096 Sep 10 16:57 images\n",
            "drwxr-xr-x 3 root root    4096 Sep 10 16:59 test_labels\n",
            "drwxr-xr-x 3 root root    4096 Sep 10 16:59 train_labels\n",
            "-rw-r--r-- 1 root root     417 Sep 10 16:59 test_labels.csv\n",
            "-rw-r--r-- 1 root root   12286 Sep 10 16:59 train_labels.csv\n",
            "-rw-r--r-- 1 root root    5092 Sep 10 16:59 label_map.pbtxt\n",
            "-rw-r--r-- 1 root root  144779 Sep 10 17:00 test_labels.record\n",
            "-rw-r--r-- 1 root root 3911576 Sep 10 17:00 train_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMckMSJqFMyc",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the Base Model\n",
        "1. Based on the model selecting at the top of this notebook, downloading the model selected and extracting its content.\n",
        "2. Creating a dir to save the model while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvN9Cw65FQzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bc0a2997-73e8-4392-c497-50a75d1d9287"
      },
      "source": [
        "%cd /content/gun_detection/models/research\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "#selecting the model\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "#creating the downlaod link for the model selected\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "#the distination folder where the model will be saved\n",
        "fine_tune_dir = '/content/gun_detection/models/research/pretrained_model'\n",
        "\n",
        "#checks if the model has already been downloaded\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "#unzipping the file and extracting its content\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# creating an output file to save the model while training\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(fine_tune_dir)):\n",
        "    shutil.rmtree(fine_tune_dir)\n",
        "os.rename(MODEL, fine_tune_dir)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjXKVMmFk47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c428a2ed-1063-490d-dc1e-53857af14974"
      },
      "source": [
        "#checking the content of the pretrained model.\n",
        "# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n",
        "!echo {fine_tune_dir}\n",
        "!ls -alh {fine_tune_dir}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 24 root   root  4.0K Sep 10 17:00 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnjQgJZiGAcA",
        "colab_type": "text"
      },
      "source": [
        "## Configuring the Training Pipeline\n",
        "1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n",
        "2. Adding some Image augmentation.\n",
        "3. Creating a directory to save the model at each checkpoint while training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az14XVo31Ujp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "fc326ae7-20de-4b09-dfdf-c73aafe6fb75"
      },
      "source": [
        "\n",
        "#the path to the folder containing all the sample config files\n",
        "CONFIG_BASE = \"/content/gun_detection/models/research/object_detection/samples/configs/\"\n",
        "\n",
        "#path to the specified model's config file\n",
        "model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n",
        "model_pipline"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT3m6pbXpN_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the sample config file that is provided by the tf model\n",
        "#!cat /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfsl5CsDGY3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "262cd665-e0fe-49b7-b8ae-04fe95fa94dd"
      },
      "source": [
        "#editing the configuration file to add the path for the TFRecords files, pbtxt,batch_size,num_steps,num_classes.\n",
        "# any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) would be editted here\n",
        "\n",
        "%%writefile {model_pipline}\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 1 # number of classes to be detected\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    # all images will be resized to the below W x H.\n",
        "    image_resizer { \n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        #use_dropout: false\n",
        "        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "            # weight: 0.00004\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            # weight: 0.00004\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000 \n",
        "        iou_threshold: 0.95\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        \n",
        "        #adjust this to the max number of objects per class. \n",
        "        # ex, in my case, i have one pistol in most of the images.\n",
        "        # . there are some images with more than one up to 16.\n",
        "        max_detections_per_class: 16\n",
        "        # max number of detections among all classes. I have 1 class only so\n",
        "        max_total_detections: 16\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 16 # training batch size\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.003\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "\n",
        "  #the path to the pretrained model. \n",
        "  fine_tune_checkpoint: \"/content/gun_detection/models/research/pretrained_model/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000 \n",
        "  \n",
        "\n",
        "  #data augmentaion is done here, you can remove or add more.\n",
        "  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n",
        "  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n",
        "  \n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_adjust_contrast {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    #path to the training TFRecord\n",
        "    input_path: \"/content/gun_detection/data/train_labels.record\"\n",
        "  }\n",
        "  #path to the label map \n",
        "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n",
        "  num_examples: 599\n",
        "  # the number of images to disply in Tensorboard while training\n",
        "  num_visualizations: 20\n",
        "\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  #max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "      \n",
        "    #path to the testing TFRecord\n",
        "    input_path: \"/content/gun_detection/data/test_labels.record\"\n",
        "  }\n",
        "  #path to the label map \n",
        "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXXZLVEG8sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where the model will be saved at each checkpoint while training \n",
        "model_dir = 'training/'\n",
        "\n",
        "# Optionally: remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vAGvftxHu8K",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard\n",
        "1. Downlaoding and unzipping Tensorboard\n",
        "2. creating a link to visualize multiple graph while training.\n",
        "\n",
        "\n",
        "notes: \n",
        "  1. Tensorboard will not log any files until the training starts. \n",
        "  2. a max of 20 connection per minute is allowed when using ngrok, you will not be able to access tensorboard while the model is logging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ucxlc5HxHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1115dd30-507a-42eb-d10f-e609880b9725"
      },
      "source": [
        "#downlaoding ngrok to be able to access tensorboard on google colab\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-10 17:01:26--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.71.209.190, 34.206.168.28, 52.21.175.83, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.71.209.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  22.7MB/s    in 0.6s    \n",
            "\n",
            "2020-09-10 17:01:27 (22.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9ufxr7IAdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idsi9zyNIIsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b38f404-197b-4c46-f2a4-cd847cc74d87"
      },
      "source": [
        "#The link to tensorboard.\n",
        "#works after the training starts.\n",
        "\n",
        "### note: if you didnt get a link as output, rerun this cell and the one above\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://344851fa232b.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuJcAPZFIfu7",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "Finally training the model!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnKt6g0_IgOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afef9fb5-2689-4d85-bdad-9cf86d7728a1"
      },
      "source": [
        "\n",
        "!python3 /content/gun_detection/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={model_pipline}\\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0910 17:07:41.456714 140000138229632 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0910 17:07:41.456923 140000138229632 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0910 17:07:41.457014 140000138229632 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0910 17:07:41.457096 140000138229632 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0910 17:07:41.457173 140000138229632 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0910 17:07:41.457270 140000138229632 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0910 17:07:41.457485 140000138229632 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f53e6e2b7f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0910 17:07:41.457894 140000138229632 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f53e6e2b7f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f53e6e2e488>) includes params argument, but params are not passed to Estimator.\n",
            "W0910 17:07:41.458106 140000138229632 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f53e6e2e488>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0910 17:07:41.458913 140000138229632 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0910 17:07:41.459092 140000138229632 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0910 17:07:41.459313 140000138229632 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0910 17:07:41.486022 140000138229632 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0910 17:07:41.529934 140000138229632 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0910 17:07:41.534938 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0910 17:07:41.554377 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53e4e102e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 17:07:41.587980 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53e4e102e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f54064f5d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 17:07:41.793044 140000138229632 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f54064f5d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0910 17:07:41.798309 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0910 17:07:41.805081 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0910 17:07:41.906921 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0910 17:07:42.752032 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 17:07:43.277989 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0910 17:07:43.532073 140000138229632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:07:45.990181 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:07:46.154984 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:07:46.192584 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:07:46.228492 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:07:46.264276 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:07:46.304221 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0910 17:07:51.057041 140000138229632 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 17:07:56.971036 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0910 17:07:56.972366 140000138229632 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 17:08:00.158939 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 17:08:00.170526: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-09-10 17:08:00.170795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x312b9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-10 17:08:00.170829: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-09-10 17:08:00.194699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-09-10 17:08:00.354722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:08:00.355234: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x312bb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-10 17:08:00.355266: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-09-10 17:08:00.355790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:08:00.356145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 17:08:00.364246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 17:08:00.616053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 17:08:00.733438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 17:08:00.779257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 17:08:01.023391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 17:08:01.068112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 17:08:01.549413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 17:08:01.549668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:08:01.550195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:08:01.550561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 17:08:01.565794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 17:08:01.569435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 17:08:01.569473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 17:08:01.569490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 17:08:01.570461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:08:01.570937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:08:01.571292: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-09-10 17:08:01.571352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-0\n",
            "I0910 17:08:01.573811 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0910 17:08:12.119525 140000138229632 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 17:08:13.265836 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 17:08:13.579394 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0910 17:08:22.160148 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-09-10 17:08:30.932864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 17:08:35.391483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 15.51249, step = 0\n",
            "I0910 17:08:41.710908 140000138229632 basic_session_run_hooks.py:262] loss = 15.51249, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.02432\n",
            "I0910 17:10:19.335931 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.02432\n",
            "INFO:tensorflow:loss = 6.226447, step = 100 (97.626 sec)\n",
            "I0910 17:10:19.337150 140000138229632 basic_session_run_hooks.py:260] loss = 6.226447, step = 100 (97.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.07949\n",
            "I0910 17:11:51.972277 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.07949\n",
            "INFO:tensorflow:loss = 5.5845346, step = 200 (92.636 sec)\n",
            "I0910 17:11:51.973659 140000138229632 basic_session_run_hooks.py:260] loss = 5.5845346, step = 200 (92.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.07286\n",
            "I0910 17:13:25.180821 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.07286\n",
            "INFO:tensorflow:loss = 4.940019, step = 300 (93.209 sec)\n",
            "I0910 17:13:25.182191 140000138229632 basic_session_run_hooks.py:260] loss = 4.940019, step = 300 (93.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.0643\n",
            "I0910 17:14:59.138904 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.0643\n",
            "INFO:tensorflow:loss = 3.8263986, step = 400 (93.958 sec)\n",
            "I0910 17:14:59.140157 140000138229632 basic_session_run_hooks.py:260] loss = 3.8263986, step = 400 (93.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.07106\n",
            "I0910 17:16:32.504680 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.07106\n",
            "INFO:tensorflow:loss = 4.772814, step = 500 (93.367 sec)\n",
            "I0910 17:16:32.507032 140000138229632 basic_session_run_hooks.py:260] loss = 4.772814, step = 500 (93.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.08735\n",
            "I0910 17:18:04.471023 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.08735\n",
            "INFO:tensorflow:loss = 3.3586345, step = 600 (91.965 sec)\n",
            "I0910 17:18:04.472125 140000138229632 basic_session_run_hooks.py:260] loss = 3.3586345, step = 600 (91.965 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 623 into training/model.ckpt.\n",
            "I0910 17:18:24.416355 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 623 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53d0328ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 17:18:25.934634 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53d0328ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53dfb19620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 17:18:26.105931 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53dfb19620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 17:18:26.601419 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:18:28.700955 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:18:28.731447 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:18:28.765635 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:18:28.795288 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:18:28.824452 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:18:28.854353 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/eval_util.py:879: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0910 17:18:29.545253 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/eval_util.py:879: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0910 17:18:29.770896 140000138229632 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 17:18:30.374658 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T17:18:30Z\n",
            "I0910 17:18:30.392056 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T17:18:30Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 17:18:30.831947 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 17:18:30.833249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:18:30.833611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 17:18:30.833729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 17:18:30.833766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 17:18:30.833791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 17:18:30.833820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 17:18:30.833847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 17:18:30.833870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 17:18:30.833895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 17:18:30.834014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:18:30.834403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:18:30.834668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 17:18:30.834729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 17:18:30.834747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 17:18:30.834762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 17:18:30.834897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:18:30.835243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:18:30.835545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-623\n",
            "I0910 17:18:30.836598 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-623\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 17:18:31.742131 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 17:18:31.865338 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 17:18:34.082385 139997960386304 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 17:18:34.084237 139997960386304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 17:18:34.085080 139997960386304 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-17:18:34\n",
            "I0910 17:18:34.305650 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-17:18:34\n",
            "INFO:tensorflow:Saving dict for global step 623: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 5.3072915, Loss/localization_loss = 4.313662, Loss/regularization_loss = 1.0775421, Loss/total_loss = 10.698496, global_step = 623, learning_rate = 0.003, loss = 10.698496\n",
            "I0910 17:18:34.305901 140000138229632 estimator.py:2049] Saving dict for global step 623: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 5.3072915, Loss/localization_loss = 4.313662, Loss/regularization_loss = 1.0775421, Loss/total_loss = 10.698496, global_step = 623, learning_rate = 0.003, loss = 10.698496\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 623: training/model.ckpt-623\n",
            "I0910 17:18:35.245320 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 623: training/model.ckpt-623\n",
            "INFO:tensorflow:global_step/sec: 0.971282\n",
            "I0910 17:19:47.427712 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 0.971282\n",
            "INFO:tensorflow:loss = 3.8414955, step = 700 (102.957 sec)\n",
            "I0910 17:19:47.429053 140000138229632 basic_session_run_hooks.py:260] loss = 3.8414955, step = 700 (102.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10531\n",
            "I0910 17:21:17.900040 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10531\n",
            "INFO:tensorflow:loss = 3.3830311, step = 800 (90.472 sec)\n",
            "I0910 17:21:17.901239 140000138229632 basic_session_run_hooks.py:260] loss = 3.3830311, step = 800 (90.472 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.09282\n",
            "I0910 17:22:49.406065 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.09282\n",
            "INFO:tensorflow:loss = 2.530397, step = 900 (91.506 sec)\n",
            "I0910 17:22:49.407174 140000138229632 basic_session_run_hooks.py:260] loss = 2.530397, step = 900 (91.506 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.08674\n",
            "I0910 17:24:21.424712 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.08674\n",
            "INFO:tensorflow:loss = 3.1841445, step = 1000 (92.019 sec)\n",
            "I0910 17:24:21.425760 140000138229632 basic_session_run_hooks.py:260] loss = 3.1841445, step = 1000 (92.019 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.08473\n",
            "I0910 17:25:53.613347 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.08473\n",
            "INFO:tensorflow:loss = 2.4959612, step = 1100 (92.189 sec)\n",
            "I0910 17:25:53.614715 140000138229632 basic_session_run_hooks.py:260] loss = 2.4959612, step = 1100 (92.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10007\n",
            "I0910 17:27:24.516428 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10007\n",
            "INFO:tensorflow:loss = 2.5101643, step = 1200 (90.903 sec)\n",
            "I0910 17:27:24.517657 140000138229632 basic_session_run_hooks.py:260] loss = 2.5101643, step = 1200 (90.903 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1267 into training/model.ckpt.\n",
            "I0910 17:28:24.687174 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 1267 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53d00b7198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 17:28:26.018075 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53d00b7198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53742a7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 17:28:26.191428 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53742a7620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 17:28:26.718751 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:28:28.771017 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:28:28.801055 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:28:28.830563 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:28:28.859660 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:28:28.889166 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:28:28.918958 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 17:28:30.299828 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T17:28:30Z\n",
            "I0910 17:28:30.315081 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T17:28:30Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 17:28:30.701776 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 17:28:30.702475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:28:30.702800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 17:28:30.702909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 17:28:30.702936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 17:28:30.702956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 17:28:30.702981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 17:28:30.703000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 17:28:30.703018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 17:28:30.703037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 17:28:30.703149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:28:30.703522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:28:30.703763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 17:28:30.703808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 17:28:30.703821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 17:28:30.703829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 17:28:30.703941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:28:30.704248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:28:30.704497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1267\n",
            "I0910 17:28:30.705576 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-1267\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 17:28:31.545974 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 17:28:31.658262 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 17:28:33.512578 139997960386304 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 17:28:33.512921 139997960386304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 17:28:33.513236 139997960386304 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-17:28:33\n",
            "I0910 17:28:33.727277 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-17:28:33\n",
            "INFO:tensorflow:Saving dict for global step 1267: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.614601, Loss/localization_loss = 3.5035522, Loss/regularization_loss = 1.0541503, Loss/total_loss = 11.172304, global_step = 1267, learning_rate = 0.003, loss = 11.172304\n",
            "I0910 17:28:33.727579 140000138229632 estimator.py:2049] Saving dict for global step 1267: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.614601, Loss/localization_loss = 3.5035522, Loss/regularization_loss = 1.0541503, Loss/total_loss = 11.172304, global_step = 1267, learning_rate = 0.003, loss = 11.172304\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1267: training/model.ckpt-1267\n",
            "I0910 17:28:33.728584 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1267: training/model.ckpt-1267\n",
            "INFO:tensorflow:global_step/sec: 0.996687\n",
            "I0910 17:29:04.848807 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 0.996687\n",
            "INFO:tensorflow:loss = 2.7088494, step = 1300 (100.333 sec)\n",
            "I0910 17:29:04.850300 140000138229632 basic_session_run_hooks.py:260] loss = 2.7088494, step = 1300 (100.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11161\n",
            "I0910 17:30:34.808613 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11161\n",
            "INFO:tensorflow:loss = 2.1968877, step = 1400 (89.959 sec)\n",
            "I0910 17:30:34.809713 140000138229632 basic_session_run_hooks.py:260] loss = 2.1968877, step = 1400 (89.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10146\n",
            "I0910 17:32:05.596857 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10146\n",
            "INFO:tensorflow:loss = 2.5688376, step = 1500 (90.788 sec)\n",
            "I0910 17:32:05.597901 140000138229632 basic_session_run_hooks.py:260] loss = 2.5688376, step = 1500 (90.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.1013\n",
            "I0910 17:33:36.398432 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.1013\n",
            "INFO:tensorflow:loss = 2.1380851, step = 1600 (90.802 sec)\n",
            "I0910 17:33:36.399592 140000138229632 basic_session_run_hooks.py:260] loss = 2.1380851, step = 1600 (90.802 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.0919\n",
            "I0910 17:35:07.981624 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.0919\n",
            "INFO:tensorflow:loss = 2.2495058, step = 1700 (91.583 sec)\n",
            "I0910 17:35:07.982681 140000138229632 basic_session_run_hooks.py:260] loss = 2.2495058, step = 1700 (91.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.08956\n",
            "I0910 17:36:39.761884 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.08956\n",
            "INFO:tensorflow:loss = 2.6754534, step = 1800 (91.781 sec)\n",
            "I0910 17:36:39.763415 140000138229632 basic_session_run_hooks.py:260] loss = 2.6754534, step = 1800 (91.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10714\n",
            "I0910 17:38:10.084233 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10714\n",
            "INFO:tensorflow:loss = 2.6014166, step = 1900 (90.322 sec)\n",
            "I0910 17:38:10.085516 140000138229632 basic_session_run_hooks.py:260] loss = 2.6014166, step = 1900 (90.322 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1917 into training/model.ckpt.\n",
            "I0910 17:38:24.718645 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 1917 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5226e4e048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 17:38:26.054759 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5226e4e048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5226e85ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 17:38:26.225640 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5226e85ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 17:38:26.742885 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:38:28.803447 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:38:28.835159 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:38:28.866139 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:38:29.276489 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:38:29.306292 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:38:29.335592 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 17:38:30.710237 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T17:38:30Z\n",
            "I0910 17:38:30.725533 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T17:38:30Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 17:38:31.111504 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 17:38:31.112191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:38:31.112550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 17:38:31.112669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 17:38:31.112698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 17:38:31.112720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 17:38:31.112746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 17:38:31.112767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 17:38:31.112786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 17:38:31.112806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 17:38:31.112930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:38:31.113339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:38:31.113612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 17:38:31.113673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 17:38:31.113687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 17:38:31.113696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 17:38:31.113823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:38:31.114161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:38:31.114411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1917\n",
            "I0910 17:38:31.115516 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-1917\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 17:38:31.957702 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 17:38:32.077286 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 17:38:33.937665 139997960386304 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 17:38:33.938115 139997960386304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 17:38:33.938874 139997960386304 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-17:38:34\n",
            "I0910 17:38:34.155358 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-17:38:34\n",
            "INFO:tensorflow:Saving dict for global step 1917: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 8.646046, Loss/localization_loss = 3.0608175, Loss/regularization_loss = 1.0288403, Loss/total_loss = 12.735703, global_step = 1917, learning_rate = 0.003, loss = 12.735703\n",
            "I0910 17:38:34.155629 140000138229632 estimator.py:2049] Saving dict for global step 1917: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 8.646046, Loss/localization_loss = 3.0608175, Loss/regularization_loss = 1.0288403, Loss/total_loss = 12.735703, global_step = 1917, learning_rate = 0.003, loss = 12.735703\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1917: training/model.ckpt-1917\n",
            "I0910 17:38:34.156635 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1917: training/model.ckpt-1917\n",
            "INFO:tensorflow:global_step/sec: 1.00212\n",
            "I0910 17:39:49.872571 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.00212\n",
            "INFO:tensorflow:loss = 2.1706214, step = 2000 (99.788 sec)\n",
            "I0910 17:39:49.873646 140000138229632 basic_session_run_hooks.py:260] loss = 2.1706214, step = 2000 (99.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10144\n",
            "I0910 17:41:20.662698 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10144\n",
            "INFO:tensorflow:loss = 2.2704782, step = 2100 (90.790 sec)\n",
            "I0910 17:41:20.663783 140000138229632 basic_session_run_hooks.py:260] loss = 2.2704782, step = 2100 (90.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.0987\n",
            "I0910 17:42:51.679185 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.0987\n",
            "INFO:tensorflow:loss = 2.4826972, step = 2200 (91.016 sec)\n",
            "I0910 17:42:51.680256 140000138229632 basic_session_run_hooks.py:260] loss = 2.4826972, step = 2200 (91.016 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10586\n",
            "I0910 17:44:22.106379 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10586\n",
            "INFO:tensorflow:loss = 1.796124, step = 2300 (90.427 sec)\n",
            "I0910 17:44:22.107542 140000138229632 basic_session_run_hooks.py:260] loss = 1.796124, step = 2300 (90.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10578\n",
            "I0910 17:45:52.540098 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10578\n",
            "INFO:tensorflow:loss = 1.7499269, step = 2400 (90.434 sec)\n",
            "I0910 17:45:52.541182 140000138229632 basic_session_run_hooks.py:260] loss = 1.7499269, step = 2400 (90.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10898\n",
            "I0910 17:47:22.713468 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10898\n",
            "INFO:tensorflow:loss = 1.9315884, step = 2500 (90.174 sec)\n",
            "I0910 17:47:22.714766 140000138229632 basic_session_run_hooks.py:260] loss = 1.9315884, step = 2500 (90.174 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2569 into training/model.ckpt.\n",
            "I0910 17:48:24.792631 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 2569 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5227661cc0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 17:48:26.225022 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5227661cc0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53741e0f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 17:48:26.401201 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53741e0f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 17:48:26.870530 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:48:28.845177 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:48:28.877418 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:48:28.909178 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:48:28.944936 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:48:28.977699 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:48:29.006126 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 17:48:30.363130 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T17:48:30Z\n",
            "I0910 17:48:30.378428 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T17:48:30Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 17:48:30.772490 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 17:48:30.773318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:48:30.773677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 17:48:30.773783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 17:48:30.773808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 17:48:30.773830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 17:48:30.773852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 17:48:30.773873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 17:48:30.773892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 17:48:30.773911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 17:48:30.774028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:48:30.774406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:48:30.774668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 17:48:30.774715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 17:48:30.774730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 17:48:30.774739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 17:48:30.774870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:48:30.775203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:48:30.775476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2569\n",
            "I0910 17:48:30.776578 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-2569\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 17:48:31.637352 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 17:48:31.751253 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 17:48:33.513182 139997968779008 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 17:48:33.513624 139997968779008 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 17:48:33.514047 139997968779008 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-17:48:33\n",
            "I0910 17:48:33.726070 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-17:48:33\n",
            "INFO:tensorflow:Saving dict for global step 2569: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 10.485669, Loss/localization_loss = 2.2334106, Loss/regularization_loss = 1.0031157, Loss/total_loss = 13.722196, global_step = 2569, learning_rate = 0.003, loss = 13.722196\n",
            "I0910 17:48:33.726319 140000138229632 estimator.py:2049] Saving dict for global step 2569: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 10.485669, Loss/localization_loss = 2.2334106, Loss/regularization_loss = 1.0031157, Loss/total_loss = 13.722196, global_step = 2569, learning_rate = 0.003, loss = 13.722196\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2569: training/model.ckpt-2569\n",
            "I0910 17:48:33.727356 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2569: training/model.ckpt-2569\n",
            "INFO:tensorflow:global_step/sec: 1.00115\n",
            "I0910 17:49:02.599002 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.00115\n",
            "INFO:tensorflow:loss = 1.9751364, step = 2600 (99.885 sec)\n",
            "I0910 17:49:02.600090 140000138229632 basic_session_run_hooks.py:260] loss = 1.9751364, step = 2600 (99.885 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10911\n",
            "I0910 17:50:32.761301 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10911\n",
            "INFO:tensorflow:loss = 2.3969917, step = 2700 (90.163 sec)\n",
            "I0910 17:50:32.762670 140000138229632 basic_session_run_hooks.py:260] loss = 2.3969917, step = 2700 (90.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10632\n",
            "I0910 17:52:03.151392 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10632\n",
            "INFO:tensorflow:loss = 2.3113797, step = 2800 (90.390 sec)\n",
            "I0910 17:52:03.152607 140000138229632 basic_session_run_hooks.py:260] loss = 2.3113797, step = 2800 (90.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10658\n",
            "I0910 17:53:33.519677 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10658\n",
            "INFO:tensorflow:loss = 1.8204209, step = 2900 (90.368 sec)\n",
            "I0910 17:53:33.521109 140000138229632 basic_session_run_hooks.py:260] loss = 1.8204209, step = 2900 (90.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10475\n",
            "I0910 17:55:04.037636 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10475\n",
            "INFO:tensorflow:loss = 1.864855, step = 3000 (90.518 sec)\n",
            "I0910 17:55:04.038789 140000138229632 basic_session_run_hooks.py:260] loss = 1.864855, step = 3000 (90.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10904\n",
            "I0910 17:56:34.206093 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10904\n",
            "INFO:tensorflow:loss = 2.3973806, step = 3100 (90.169 sec)\n",
            "I0910 17:56:34.207388 140000138229632 basic_session_run_hooks.py:260] loss = 2.3973806, step = 3100 (90.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10688\n",
            "I0910 17:58:04.549965 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10688\n",
            "INFO:tensorflow:loss = 2.3190699, step = 3200 (90.344 sec)\n",
            "I0910 17:58:04.551175 140000138229632 basic_session_run_hooks.py:260] loss = 2.3190699, step = 3200 (90.344 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3224 into training/model.ckpt.\n",
            "I0910 17:58:25.064770 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 3224 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0910 17:58:25.163362 140000138229632 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5229e7cc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 17:58:26.420657 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5229e7cc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53740bde18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 17:58:26.591343 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f53740bde18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 17:58:27.085057 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:58:29.525107 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:58:29.554480 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:58:29.587448 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:58:29.617266 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:58:29.646717 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 17:58:29.676117 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 17:58:31.058482 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T17:58:31Z\n",
            "I0910 17:58:31.075049 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T17:58:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 17:58:31.481256 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 17:58:31.482136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:58:31.482480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 17:58:31.482655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 17:58:31.482683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 17:58:31.482719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 17:58:31.482738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 17:58:31.482757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 17:58:31.482779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 17:58:31.482808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 17:58:31.482931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:58:31.483624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:58:31.484187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 17:58:31.484293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 17:58:31.484310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 17:58:31.484318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 17:58:31.484507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:58:31.486362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 17:58:31.486736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3224\n",
            "I0910 17:58:31.487855 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-3224\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 17:58:32.365641 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 17:58:32.486605 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 17:58:34.328201 139997968779008 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 17:58:34.328566 139997968779008 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 17:58:34.328857 139997968779008 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-17:58:34\n",
            "I0910 17:58:34.555778 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-17:58:34\n",
            "INFO:tensorflow:Saving dict for global step 3224: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 11.480164, Loss/localization_loss = 2.2382412, Loss/regularization_loss = 0.9775269, Loss/total_loss = 14.695931, global_step = 3224, learning_rate = 0.003, loss = 14.695931\n",
            "I0910 17:58:34.556053 140000138229632 estimator.py:2049] Saving dict for global step 3224: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 11.480164, Loss/localization_loss = 2.2382412, Loss/regularization_loss = 0.9775269, Loss/total_loss = 14.695931, global_step = 3224, learning_rate = 0.003, loss = 14.695931\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3224: training/model.ckpt-3224\n",
            "I0910 17:58:34.557106 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3224: training/model.ckpt-3224\n",
            "INFO:tensorflow:global_step/sec: 1.00903\n",
            "I0910 17:59:43.655512 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.00903\n",
            "INFO:tensorflow:loss = 1.8357017, step = 3300 (99.105 sec)\n",
            "I0910 17:59:43.656526 140000138229632 basic_session_run_hooks.py:260] loss = 1.8357017, step = 3300 (99.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10887\n",
            "I0910 18:01:13.837060 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10887\n",
            "INFO:tensorflow:loss = 2.4917102, step = 3400 (90.182 sec)\n",
            "I0910 18:01:13.838462 140000138229632 basic_session_run_hooks.py:260] loss = 2.4917102, step = 3400 (90.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10415\n",
            "I0910 18:02:44.404219 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10415\n",
            "INFO:tensorflow:loss = 2.2230227, step = 3500 (90.567 sec)\n",
            "I0910 18:02:44.405583 140000138229632 basic_session_run_hooks.py:260] loss = 2.2230227, step = 3500 (90.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10271\n",
            "I0910 18:04:15.089796 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10271\n",
            "INFO:tensorflow:loss = 1.6836042, step = 3600 (90.685 sec)\n",
            "I0910 18:04:15.090956 140000138229632 basic_session_run_hooks.py:260] loss = 1.6836042, step = 3600 (90.685 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10369\n",
            "I0910 18:05:45.694823 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10369\n",
            "INFO:tensorflow:loss = 1.8327767, step = 3700 (90.605 sec)\n",
            "I0910 18:05:45.695863 140000138229632 basic_session_run_hooks.py:260] loss = 1.8327767, step = 3700 (90.605 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11801\n",
            "I0910 18:07:15.139675 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11801\n",
            "INFO:tensorflow:loss = 1.641581, step = 3800 (89.445 sec)\n",
            "I0910 18:07:15.140903 140000138229632 basic_session_run_hooks.py:260] loss = 1.641581, step = 3800 (89.445 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3879 into training/model.ckpt.\n",
            "I0910 18:08:25.167440 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 3879 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f522987d588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 18:08:26.506393 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f522987d588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5229ccbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 18:08:26.678320 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5229ccbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 18:08:27.164712 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:08:29.264849 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:08:29.294115 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:08:29.323019 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:08:29.351707 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:08:29.379882 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:08:29.409626 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 18:08:31.055448 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T18:08:31Z\n",
            "I0910 18:08:31.072091 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T18:08:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 18:08:31.459489 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 18:08:31.460169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:08:31.460550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 18:08:31.460656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 18:08:31.460680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 18:08:31.460700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 18:08:31.460719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 18:08:31.460737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 18:08:31.460754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 18:08:31.460773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 18:08:31.460888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:08:31.461259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:08:31.461519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 18:08:31.461566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 18:08:31.461580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 18:08:31.461589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 18:08:31.461714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:08:31.462076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:08:31.462373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3879\n",
            "I0910 18:08:31.463405 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-3879\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 18:08:32.342602 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 18:08:32.462406 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 18:08:34.288411 139997968779008 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 18:08:34.288809 139997968779008 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 18:08:34.289250 139997968779008 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-18:08:34\n",
            "I0910 18:08:34.504894 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-18:08:34\n",
            "INFO:tensorflow:Saving dict for global step 3879: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 12.449607, Loss/localization_loss = 2.5019174, Loss/regularization_loss = 0.9524565, Loss/total_loss = 15.903981, global_step = 3879, learning_rate = 0.003, loss = 15.903981\n",
            "I0910 18:08:34.505144 140000138229632 estimator.py:2049] Saving dict for global step 3879: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 12.449607, Loss/localization_loss = 2.5019174, Loss/regularization_loss = 0.9524565, Loss/total_loss = 15.903981, global_step = 3879, learning_rate = 0.003, loss = 15.903981\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3879: training/model.ckpt-3879\n",
            "I0910 18:08:34.506133 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3879: training/model.ckpt-3879\n",
            "INFO:tensorflow:global_step/sec: 1.0089\n",
            "I0910 18:08:54.257159 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.0089\n",
            "INFO:tensorflow:loss = 1.7970481, step = 3900 (99.117 sec)\n",
            "I0910 18:08:54.258068 140000138229632 basic_session_run_hooks.py:260] loss = 1.7970481, step = 3900 (99.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11197\n",
            "I0910 18:10:24.187738 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11197\n",
            "INFO:tensorflow:loss = 1.948229, step = 4000 (89.931 sec)\n",
            "I0910 18:10:24.188770 140000138229632 basic_session_run_hooks.py:260] loss = 1.948229, step = 4000 (89.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.09957\n",
            "I0910 18:11:55.132441 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.09957\n",
            "INFO:tensorflow:loss = 1.7897937, step = 4100 (90.945 sec)\n",
            "I0910 18:11:55.133560 140000138229632 basic_session_run_hooks.py:260] loss = 1.7897937, step = 4100 (90.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11132\n",
            "I0910 18:13:25.115178 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11132\n",
            "INFO:tensorflow:loss = 1.8168905, step = 4200 (89.983 sec)\n",
            "I0910 18:13:25.116194 140000138229632 basic_session_run_hooks.py:260] loss = 1.8168905, step = 4200 (89.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11455\n",
            "I0910 18:14:54.837707 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11455\n",
            "INFO:tensorflow:loss = 1.479104, step = 4300 (89.723 sec)\n",
            "I0910 18:14:54.838864 140000138229632 basic_session_run_hooks.py:260] loss = 1.479104, step = 4300 (89.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10494\n",
            "I0910 18:16:25.340341 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10494\n",
            "INFO:tensorflow:loss = 1.5813076, step = 4400 (90.503 sec)\n",
            "I0910 18:16:25.341637 140000138229632 basic_session_run_hooks.py:260] loss = 1.5813076, step = 4400 (90.503 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10513\n",
            "I0910 18:17:55.827480 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10513\n",
            "INFO:tensorflow:loss = 1.7615602, step = 4500 (90.487 sec)\n",
            "I0910 18:17:55.828719 140000138229632 basic_session_run_hooks.py:260] loss = 1.7615602, step = 4500 (90.487 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4534 into training/model.ckpt.\n",
            "I0910 18:18:25.961317 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 4534 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53d01e7b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 18:18:27.368292 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53d01e7b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5229ccbae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 18:18:27.529676 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5229ccbae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 18:18:28.002077 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:18:29.964755 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:18:29.994920 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:18:30.023461 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:18:30.052254 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:18:30.080554 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:18:30.113266 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 18:18:31.522884 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T18:18:31Z\n",
            "I0910 18:18:31.539835 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T18:18:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 18:18:31.963381 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 18:18:31.964031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:18:31.964373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 18:18:31.964515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 18:18:31.964542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 18:18:31.964562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 18:18:31.964582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 18:18:31.964602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 18:18:31.964621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 18:18:31.964641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 18:18:31.964765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:18:31.965099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:18:31.965376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 18:18:31.965436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 18:18:31.965450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 18:18:31.965459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 18:18:31.965586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:18:31.965935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:18:31.966268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4534\n",
            "I0910 18:18:31.967310 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-4534\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 18:18:32.871906 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 18:18:32.995279 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 18:18:34.834671 139997968779008 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 18:18:34.835298 139997968779008 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 18:18:34.835809 139997968779008 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-18:18:35\n",
            "I0910 18:18:35.062185 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-18:18:35\n",
            "INFO:tensorflow:Saving dict for global step 4534: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 13.522722, Loss/localization_loss = 2.4002337, Loss/regularization_loss = 0.9280462, Loss/total_loss = 16.851002, global_step = 4534, learning_rate = 0.003, loss = 16.851002\n",
            "I0910 18:18:35.062488 140000138229632 estimator.py:2049] Saving dict for global step 4534: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 13.522722, Loss/localization_loss = 2.4002337, Loss/regularization_loss = 0.9280462, Loss/total_loss = 16.851002, global_step = 4534, learning_rate = 0.003, loss = 16.851002\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4534: training/model.ckpt-4534\n",
            "I0910 18:18:35.063611 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4534: training/model.ckpt-4534\n",
            "INFO:tensorflow:global_step/sec: 1.00221\n",
            "I0910 18:19:35.606615 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.00221\n",
            "INFO:tensorflow:loss = 2.0413897, step = 4600 (99.779 sec)\n",
            "I0910 18:19:35.607823 140000138229632 basic_session_run_hooks.py:260] loss = 2.0413897, step = 4600 (99.779 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.09937\n",
            "I0910 18:21:06.567941 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.09937\n",
            "INFO:tensorflow:loss = 1.7668136, step = 4700 (90.961 sec)\n",
            "I0910 18:21:06.569255 140000138229632 basic_session_run_hooks.py:260] loss = 1.7668136, step = 4700 (90.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10987\n",
            "I0910 18:22:36.668380 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10987\n",
            "INFO:tensorflow:loss = 1.7052822, step = 4800 (90.100 sec)\n",
            "I0910 18:22:36.669552 140000138229632 basic_session_run_hooks.py:260] loss = 1.7052822, step = 4800 (90.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10964\n",
            "I0910 18:24:06.788061 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10964\n",
            "INFO:tensorflow:loss = 1.6834729, step = 4900 (90.120 sec)\n",
            "I0910 18:24:06.789144 140000138229632 basic_session_run_hooks.py:260] loss = 1.6834729, step = 4900 (90.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10352\n",
            "I0910 18:25:37.406912 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10352\n",
            "INFO:tensorflow:loss = 1.7296418, step = 5000 (90.619 sec)\n",
            "I0910 18:25:37.408160 140000138229632 basic_session_run_hooks.py:260] loss = 1.7296418, step = 5000 (90.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10957\n",
            "I0910 18:27:07.532085 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10957\n",
            "INFO:tensorflow:loss = 1.4560919, step = 5100 (90.125 sec)\n",
            "I0910 18:27:07.533130 140000138229632 basic_session_run_hooks.py:260] loss = 1.4560919, step = 5100 (90.125 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5189 into training/model.ckpt.\n",
            "I0910 18:28:26.793970 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 5189 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5229217e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 18:28:28.142069 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5229217e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f52292517b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 18:28:28.311655 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f52292517b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 18:28:28.822857 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:28:30.798628 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:28:30.828075 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:28:31.231142 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:28:31.260494 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:28:31.288582 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:28:31.317087 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 18:28:32.689929 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T18:28:32Z\n",
            "I0910 18:28:32.705577 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T18:28:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 18:28:33.093277 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 18:28:33.094227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:28:33.094611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 18:28:33.094768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 18:28:33.094804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 18:28:33.094826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 18:28:33.094846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 18:28:33.094867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 18:28:33.094886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 18:28:33.094912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 18:28:33.095032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:28:33.095408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:28:33.095655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 18:28:33.095749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 18:28:33.095763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 18:28:33.095772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 18:28:33.095894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:28:33.096219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:28:33.096479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5189\n",
            "I0910 18:28:33.097534 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-5189\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 18:28:33.971248 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 18:28:34.102399 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 18:28:35.972091 139997968779008 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 18:28:35.972560 139997968779008 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 18:28:35.973096 139997968779008 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-18:28:36\n",
            "I0910 18:28:36.188424 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-18:28:36\n",
            "INFO:tensorflow:Saving dict for global step 5189: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.1597, Loss/localization_loss = 2.3747783, Loss/regularization_loss = 0.90434945, Loss/total_loss = 17.43883, global_step = 5189, learning_rate = 0.003, loss = 17.43883\n",
            "I0910 18:28:36.188694 140000138229632 estimator.py:2049] Saving dict for global step 5189: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.1597, Loss/localization_loss = 2.3747783, Loss/regularization_loss = 0.90434945, Loss/total_loss = 17.43883, global_step = 5189, learning_rate = 0.003, loss = 17.43883\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5189: training/model.ckpt-5189\n",
            "I0910 18:28:36.189679 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5189: training/model.ckpt-5189\n",
            "INFO:tensorflow:global_step/sec: 1.00459\n",
            "I0910 18:28:47.074958 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.00459\n",
            "INFO:tensorflow:loss = 2.1789317, step = 5200 (99.543 sec)\n",
            "I0910 18:28:47.076081 140000138229632 basic_session_run_hooks.py:260] loss = 2.1789317, step = 5200 (99.543 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11203\n",
            "I0910 18:30:17.000825 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11203\n",
            "INFO:tensorflow:loss = 1.5949523, step = 5300 (89.926 sec)\n",
            "I0910 18:30:17.002078 140000138229632 basic_session_run_hooks.py:260] loss = 1.5949523, step = 5300 (89.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10337\n",
            "I0910 18:31:47.632444 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10337\n",
            "INFO:tensorflow:loss = 1.6175749, step = 5400 (90.632 sec)\n",
            "I0910 18:31:47.633603 140000138229632 basic_session_run_hooks.py:260] loss = 1.6175749, step = 5400 (90.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10388\n",
            "I0910 18:33:18.221851 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10388\n",
            "INFO:tensorflow:loss = 1.9649533, step = 5500 (90.590 sec)\n",
            "I0910 18:33:18.223424 140000138229632 basic_session_run_hooks.py:260] loss = 1.9649533, step = 5500 (90.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10674\n",
            "I0910 18:34:48.577447 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10674\n",
            "INFO:tensorflow:loss = 1.6045414, step = 5600 (90.355 sec)\n",
            "I0910 18:34:48.578442 140000138229632 basic_session_run_hooks.py:260] loss = 1.6045414, step = 5600 (90.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.1044\n",
            "I0910 18:36:19.124277 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.1044\n",
            "INFO:tensorflow:loss = 1.39906, step = 5700 (90.547 sec)\n",
            "I0910 18:36:19.125603 140000138229632 basic_session_run_hooks.py:260] loss = 1.39906, step = 5700 (90.547 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.09636\n",
            "I0910 18:37:50.335164 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.09636\n",
            "INFO:tensorflow:loss = 1.5678684, step = 5800 (91.211 sec)\n",
            "I0910 18:37:50.336168 140000138229632 basic_session_run_hooks.py:260] loss = 1.5678684, step = 5800 (91.211 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5842 into training/model.ckpt.\n",
            "I0910 18:38:26.803881 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 5842 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f522995bda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 18:38:28.250560 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f522995bda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f522912cbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 18:38:28.421748 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f522912cbf8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 18:38:28.942502 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:38:30.885462 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:38:30.914060 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:38:30.942426 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:38:30.971673 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:38:31.002395 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:38:31.032755 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 18:38:32.465059 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T18:38:32Z\n",
            "I0910 18:38:32.481538 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T18:38:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 18:38:32.909237 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 18:38:32.910048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:38:32.910440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 18:38:32.910562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 18:38:32.910595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 18:38:32.910623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 18:38:32.910648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 18:38:32.910672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 18:38:32.910697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 18:38:32.910750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 18:38:32.910883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:38:32.911251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:38:32.911538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 18:38:32.911630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 18:38:32.911648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 18:38:32.911661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 18:38:32.911820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:38:32.912196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:38:32.912483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5842\n",
            "I0910 18:38:32.913544 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-5842\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 18:38:33.774775 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 18:38:33.893812 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 18:38:35.663466 139997960386304 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 18:38:35.663890 139997960386304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 18:38:35.664420 139997960386304 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-18:38:35\n",
            "I0910 18:38:35.885773 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-18:38:35\n",
            "INFO:tensorflow:Saving dict for global step 5842: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.319415, Loss/localization_loss = 2.4191396, Loss/regularization_loss = 0.8814832, Loss/total_loss = 17.620037, global_step = 5842, learning_rate = 0.003, loss = 17.620037\n",
            "I0910 18:38:35.886012 140000138229632 estimator.py:2049] Saving dict for global step 5842: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.319415, Loss/localization_loss = 2.4191396, Loss/regularization_loss = 0.8814832, Loss/total_loss = 17.620037, global_step = 5842, learning_rate = 0.003, loss = 17.620037\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5842: training/model.ckpt-5842\n",
            "I0910 18:38:35.886923 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5842: training/model.ckpt-5842\n",
            "INFO:tensorflow:global_step/sec: 1.01444\n",
            "I0910 18:39:28.911818 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.01444\n",
            "INFO:tensorflow:loss = 1.6674004, step = 5900 (98.577 sec)\n",
            "I0910 18:39:28.913054 140000138229632 basic_session_run_hooks.py:260] loss = 1.6674004, step = 5900 (98.577 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.1186\n",
            "I0910 18:40:58.309619 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.1186\n",
            "INFO:tensorflow:loss = 2.0856843, step = 6000 (89.398 sec)\n",
            "I0910 18:40:58.310605 140000138229632 basic_session_run_hooks.py:260] loss = 2.0856843, step = 6000 (89.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10394\n",
            "I0910 18:42:28.893986 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10394\n",
            "INFO:tensorflow:loss = 1.6483542, step = 6100 (90.585 sec)\n",
            "I0910 18:42:28.895265 140000138229632 basic_session_run_hooks.py:260] loss = 1.6483542, step = 6100 (90.585 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11851\n",
            "I0910 18:43:58.298835 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11851\n",
            "INFO:tensorflow:loss = 1.5980009, step = 6200 (89.405 sec)\n",
            "I0910 18:43:58.300111 140000138229632 basic_session_run_hooks.py:260] loss = 1.5980009, step = 6200 (89.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10469\n",
            "I0910 18:45:28.821796 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10469\n",
            "INFO:tensorflow:loss = 1.5681052, step = 6300 (90.523 sec)\n",
            "I0910 18:45:28.823107 140000138229632 basic_session_run_hooks.py:260] loss = 1.5681052, step = 6300 (90.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.09556\n",
            "I0910 18:47:00.098935 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.09556\n",
            "INFO:tensorflow:loss = 1.9213915, step = 6400 (91.277 sec)\n",
            "I0910 18:47:00.100295 140000138229632 basic_session_run_hooks.py:260] loss = 1.9213915, step = 6400 (91.277 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6497 into training/model.ckpt.\n",
            "I0910 18:48:26.908579 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 6497 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53756fec50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 18:48:28.246590 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53756fec50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f537583fe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 18:48:28.424368 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f537583fe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 18:48:28.938229 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:48:31.398101 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:48:31.429317 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:48:31.459456 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:48:31.490374 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:48:31.520813 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:48:31.551308 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 18:48:32.923105 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T18:48:32Z\n",
            "I0910 18:48:32.938839 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T18:48:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 18:48:33.322182 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 18:48:33.322972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:48:33.323304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 18:48:33.323450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 18:48:33.323478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 18:48:33.323500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 18:48:33.323522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 18:48:33.323544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 18:48:33.323562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 18:48:33.323583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 18:48:33.323702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:48:33.324036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:48:33.324276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 18:48:33.324333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 18:48:33.324347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 18:48:33.324357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 18:48:33.324483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:48:33.324832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:48:33.325089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-6497\n",
            "I0910 18:48:33.326175 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-6497\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 18:48:34.216909 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 18:48:34.343626 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 18:48:36.231148 139997960386304 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 18:48:36.231592 139997960386304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 18:48:36.232451 139997960386304 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-18:48:36\n",
            "I0910 18:48:36.448291 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-18:48:36\n",
            "INFO:tensorflow:Saving dict for global step 6497: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.648641, Loss/localization_loss = 2.2520807, Loss/regularization_loss = 0.85931134, Loss/total_loss = 17.760033, global_step = 6497, learning_rate = 0.003, loss = 17.760033\n",
            "I0910 18:48:36.448612 140000138229632 estimator.py:2049] Saving dict for global step 6497: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.648641, Loss/localization_loss = 2.2520807, Loss/regularization_loss = 0.85931134, Loss/total_loss = 17.760033, global_step = 6497, learning_rate = 0.003, loss = 17.760033\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6497: training/model.ckpt-6497\n",
            "I0910 18:48:36.449664 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6497: training/model.ckpt-6497\n",
            "INFO:tensorflow:global_step/sec: 0.999726\n",
            "I0910 18:48:40.126345 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 0.999726\n",
            "INFO:tensorflow:loss = 1.5357032, step = 6500 (100.027 sec)\n",
            "I0910 18:48:40.127448 140000138229632 basic_session_run_hooks.py:260] loss = 1.5357032, step = 6500 (100.027 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10454\n",
            "I0910 18:50:10.661381 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10454\n",
            "INFO:tensorflow:loss = 1.7290041, step = 6600 (90.535 sec)\n",
            "I0910 18:50:10.662640 140000138229632 basic_session_run_hooks.py:260] loss = 1.7290041, step = 6600 (90.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10957\n",
            "I0910 18:51:40.786379 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10957\n",
            "INFO:tensorflow:loss = 1.3548186, step = 6700 (90.125 sec)\n",
            "I0910 18:51:40.787534 140000138229632 basic_session_run_hooks.py:260] loss = 1.3548186, step = 6700 (90.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10154\n",
            "I0910 18:53:11.568104 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10154\n",
            "INFO:tensorflow:loss = 1.6434236, step = 6800 (90.782 sec)\n",
            "I0910 18:53:11.569280 140000138229632 basic_session_run_hooks.py:260] loss = 1.6434236, step = 6800 (90.782 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.11327\n",
            "I0910 18:54:41.393642 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.11327\n",
            "INFO:tensorflow:loss = 1.661849, step = 6900 (89.825 sec)\n",
            "I0910 18:54:41.394773 140000138229632 basic_session_run_hooks.py:260] loss = 1.661849, step = 6900 (89.825 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.12342\n",
            "I0910 18:56:10.407634 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.12342\n",
            "INFO:tensorflow:loss = 1.4462028, step = 7000 (89.014 sec)\n",
            "I0910 18:56:10.408928 140000138229632 basic_session_run_hooks.py:260] loss = 1.4462028, step = 7000 (89.014 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.10437\n",
            "I0910 18:57:40.956964 140000138229632 basic_session_run_hooks.py:692] global_step/sec: 1.10437\n",
            "INFO:tensorflow:loss = 1.4175587, step = 7100 (90.549 sec)\n",
            "I0910 18:57:40.958203 140000138229632 basic_session_run_hooks.py:260] loss = 1.4175587, step = 7100 (90.549 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7152 into training/model.ckpt.\n",
            "I0910 18:58:27.286165 140000138229632 basic_session_run_hooks.py:606] Saving checkpoints for 7152 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53754f2588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0910 18:58:28.646713 140000138229632 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f53754f2588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f52274cbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0910 18:58:28.811663 140000138229632 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f52274cbe18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0910 18:58:29.312937 140000138229632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:58:31.309740 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:58:31.338876 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:58:31.367591 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:58:31.396466 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:58:31.425503 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0910 18:58:31.453546 140000138229632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0910 18:58:33.120691 140000138229632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-10T18:58:33Z\n",
            "I0910 18:58:33.136368 140000138229632 evaluation.py:255] Starting evaluation at 2020-09-10T18:58:33Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0910 18:58:33.525444 140000138229632 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-10 18:58:33.526524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:58:33.527807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-10 18:58:33.527970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-10 18:58:33.528036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-10 18:58:33.528063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-10 18:58:33.528090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-10 18:58:33.528113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-10 18:58:33.528136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-10 18:58:33.528159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-10 18:58:33.528300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:58:33.528739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:58:33.529003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-10 18:58:33.529086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-10 18:58:33.529103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-10 18:58:33.529129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-10 18:58:33.529394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:58:33.529894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-10 18:58:33.531843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-7152\n",
            "I0910 18:58:33.533975 140000138229632 saver.py:1284] Restoring parameters from training/model.ckpt-7152\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0910 18:58:34.438335 140000138229632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0910 18:58:34.564167 140000138229632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1 images.\n",
            "I0910 18:58:36.384981 139997960386304 coco_evaluation.py:282] Performing evaluation on 1 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0910 18:58:36.385343 139997960386304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0910 18:58:36.385656 139997960386304 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-10-18:58:36\n",
            "I0910 18:58:36.605375 140000138229632 evaluation.py:275] Finished evaluation at 2020-09-10-18:58:36\n",
            "INFO:tensorflow:Saving dict for global step 7152: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.736383, Loss/localization_loss = 2.200467, Loss/regularization_loss = 0.83790827, Loss/total_loss = 17.77476, global_step = 7152, learning_rate = 0.003, loss = 17.77476\n",
            "I0910 18:58:36.605726 140000138229632 estimator.py:2049] Saving dict for global step 7152: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.736383, Loss/localization_loss = 2.200467, Loss/regularization_loss = 0.83790827, Loss/total_loss = 17.77476, global_step = 7152, learning_rate = 0.003, loss = 17.77476\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7152: training/model.ckpt-7152\n",
            "I0910 18:58:36.607192 140000138229632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7152: training/model.ckpt-7152\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gun_detection/models/research/object_detection/model_main.py\", line 108, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/gun_detection/models/research/object_detection/model_main.py\", line 104, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPN8liiQc7Ue",
        "colab_type": "text"
      },
      "source": [
        "## Exporting The Trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upwUdom0lTub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#the location where the exported model will be saved in.\n",
        "output_directory = '/content/gun_detection/models/research/fine_tuned_model'\n",
        "\n",
        "# goes through the model is the training/ dir and gets the last one.\n",
        "# you could choose a specfic one instead of the last\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "#exports the model specifed and inference graph\n",
        "!python /content/gun_detection/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={model_pipline} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuxDnGPM_JPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downloads the frozen model that is needed for inference\n",
        "files.download(output_directory + '/frozen_inference_graph.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTkkaGq5BpYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downlaod the label map\n",
        "files.download(DATA_BASE_PATH + '/label_map.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWr3WwzHL2vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}