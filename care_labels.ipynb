{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "care_labels.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AMlXJ2yIV8e7",
        "sv3Zm042QGJy",
        "pOfuwfPrPSMz",
        "A_tyvKnBP6qD",
        "t9C3L_r4Pi6m",
        "xMckMSJqFMyc",
        "HnjQgJZiGAcA",
        "8vAGvftxHu8K",
        "IuJcAPZFIfu7",
        "RPN8liiQc7Ue"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlXJ2yIV8e7",
        "colab_type": "text"
      },
      "source": [
        "## Choosing a pre training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3_Ns54i3HgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d3eeaa82-7791-4428-d2f9-66d6a1a52e5c"
      },
      "source": [
        "\n",
        "%tensorflow_version 1.x # Select module of the tensorflow\n",
        "# Some models to train on\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "    }\n",
        "}\n",
        "\n",
        "selected_model = 'ssd_mobilenet_v2'\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x # Select module of the tensorflow`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3Zm042QGJy",
        "colab_type": "text"
      },
      "source": [
        "## Installing Required Packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68StUELaQPS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -qq pycocotools"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERyocH9U-o2Y",
        "colab_type": "text"
      },
      "source": [
        "## General imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEVLeKXh-s23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import cv2 \n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import io\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from PIL import Image\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "import shutil\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8QeHvX6gpmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b087b6c6-e0be-4829-c2db-04edcdde104a"
      },
      "source": [
        "#tenorflow must be v1.15.2, because object detection API is removed from tf v 2.0+\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOcbTFEiPBKA",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Orgniazing Images and Annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebLK0eX_ezhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f6479de7-c59c-4afc-96a6-98f6568decb7"
      },
      "source": [
        "!git clone https://github.com/Dovahkiin169/CareLabelsData.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CareLabelsData'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 572 (delta 118), reused 121 (delta 99), pack-reused 432\u001b[K\n",
            "Receiving objects: 100% (572/572), 190.25 MiB | 53.55 MiB/s, done.\n",
            "Resolving deltas: 100% (330/330), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHPQQmhm7RLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "791c2c6f-9a03-4b13-8b33-b62464c4da03"
      },
      "source": [
        "cd CareLabelsData"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CareLabelsData\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JxCdR-c8yGp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOfuwfPrPSMz",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Images and Labels\n",
        "1. Converting annotations from xml's to two csv files for `train_labels/` and `train_labels/`.\n",
        "2. Creating a label map file that specifies the number of class (one class in this case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBHBFpWyEIDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3056ee9d-9f14-4b9a-9ab5-4186a5013ac9"
      },
      "source": [
        "%cd /content/CareLabelsData/data\n",
        "images_extension = 'jpg'\n",
        "\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text + '.' + images_extension,\n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: '{1}'\\n }}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CareLabelsData/data\n",
            "Successfully converted train_labels xml to csv.\n",
            "Successfully converted test_labels xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtfjZcD-CCdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f37ae11c-2be6-488b-8aaf-65870a66531d"
      },
      "source": [
        "!cat label_map.pbtxt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "    id: 1\n",
            "    name: 'bleaching_with_chlorine_allowed'\n",
            "    display_name: 'bleaching_with_chlorine_allowed'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 2\n",
            "    name: 'chlorine_and_non_chlorine_bleach'\n",
            "    display_name: 'chlorine_and_non_chlorine_bleach'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 3\n",
            "    name: 'do_not_bleach'\n",
            "    display_name: 'do_not_bleach'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 4\n",
            "    name: 'do_not_dry_clean'\n",
            "    display_name: 'do_not_dry_clean'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 5\n",
            "    name: 'do_not_iron'\n",
            "    display_name: 'do_not_iron'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 6\n",
            "    name: 'do_not_tumble_drying'\n",
            "    display_name: 'do_not_tumble_drying'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 7\n",
            "    name: 'do_not_wash'\n",
            "    display_name: 'do_not_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 8\n",
            "    name: 'do_not_wet_clean'\n",
            "    display_name: 'do_not_wet_clean'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 9\n",
            "    name: 'drip_dry_in_the_shade'\n",
            "    display_name: 'drip_dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 10\n",
            "    name: 'drip_dry'\n",
            "    display_name: 'drip_dry'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 11\n",
            "    name: 'dry_clean_any_solvent'\n",
            "    display_name: 'dry_clean_any_solvent'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 12\n",
            "    name: 'dry_clean_hydrocarbon_solvent_only_hcs'\n",
            "    display_name: 'dry_clean_hydrocarbon_solvent_only_hcs'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 13\n",
            "    name: 'dry_clean_tetrachloroethylene_pce_only'\n",
            "    display_name: 'dry_clean_tetrachloroethylene_pce_only'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 14\n",
            "    name: 'dry_flat_in_the_shade'\n",
            "    display_name: 'dry_flat_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 15\n",
            "    name: 'dry_flat'\n",
            "    display_name: 'dry_flat'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 16\n",
            "    name: 'dry_in_the_shade'\n",
            "    display_name: 'dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 17\n",
            "    name: 'drying_symbol'\n",
            "    display_name: 'drying_symbol'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 18\n",
            "    name: 'gentle_cleaning_with_hydrocarbon_solvents'\n",
            "    display_name: 'gentle_cleaning_with_hydrocarbon_solvents'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 19\n",
            "    name: 'gentle_cleaning_with_pce'\n",
            "    display_name: 'gentle_cleaning_with_pce'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 20\n",
            "    name: 'gentle_wet_cleaning'\n",
            "    display_name: 'gentle_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 21\n",
            "    name: 'hand_wash'\n",
            "    display_name: 'hand_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 22\n",
            "    name: 'ironing_at_high_temp'\n",
            "    display_name: 'ironing_at_high_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 23\n",
            "    name: 'ironing_at_low_temp'\n",
            "    display_name: 'ironing_at_low_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 24\n",
            "    name: 'ironing_at_med_temp'\n",
            "    display_name: 'ironing_at_med_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 25\n",
            "    name: 'ironing'\n",
            "    display_name: 'ironing'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 26\n",
            "    name: 'line_dry_in_the_shade'\n",
            "    display_name: 'line_dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 27\n",
            "    name: 'line_dry'\n",
            "    display_name: 'line_dry'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 28\n",
            "    name: 'no_steam'\n",
            "    display_name: 'no_steam'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 29\n",
            "    name: 'non_chlorine_bleach_when_needed'\n",
            "    display_name: 'non_chlorine_bleach_when_needed'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 30\n",
            "    name: 'professional_cleaning'\n",
            "    display_name: 'professional_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 31\n",
            "    name: 'professional_wet_cleaning'\n",
            "    display_name: 'professional_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 32\n",
            "    name: 'tumble_drying_low_temps'\n",
            "    display_name: 'tumble_drying_low_temps'\n",
            " }\n",
            " \n",
            "  item {\n",
            "    id: 33\n",
            "    name: 'tumble_drying_normal'\n",
            "    display_name: 'tumble_drying_normal'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 34\n",
            "    name: 'tumble_drying'\n",
            "    display_name: 'tumble_drying'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 35\n",
            "    name: 'very_gentle_cleaning_with_hydrocarbon_solvents'\n",
            "    display_name: 'very_gentle_cleaning_with_hydrocarbon_solvents'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 36\n",
            "    name: 'very_gentle_cleaning_with_pce'\n",
            "    display_name: 'very_gentle_cleaning_with_pce'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 37\n",
            "    name: 'very_gentle_wet_cleaning'\n",
            "    display_name: 'very_gentle_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 38\n",
            "    name: 'wash_at_or_below_30_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_30_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 39\n",
            "    name: 'wash_at_or_below_30_very_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_30_very_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 40\n",
            "    name: 'wash_at_or_below_30'\n",
            "    display_name: 'wash_at_or_below_30'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 41\n",
            "    name: 'wash_at_or_below_40_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_40_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 42\n",
            "    name: 'wash_at_or_below_40_very_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_40_very_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 43\n",
            "    name: 'wash_at_or_below_40'\n",
            "    display_name: 'wash_at_or_below_40'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 44\n",
            "    name: 'wash_at_or_below_50_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_50_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 45\n",
            "    name: 'wash_at_or_below_50'\n",
            "    display_name: 'wash_at_or_below_50'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 46\n",
            "    name: 'wash_at_or_below_60_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_60_mild_fine_wash'\n",
            " }\n",
            "\n",
            "   item {\n",
            "    id: 47\n",
            "    name: 'wash_at_or_below_60'\n",
            "    display_name: 'wash_at_or_below_60'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 48\n",
            "    name: 'wash_at_or_below_70'\n",
            "    display_name: 'wash_at_or_below_70'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 49\n",
            "    name: 'wash_at_or_below_90'\n",
            "    display_name: 'wash_at_or_below_90'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 50\n",
            "    name: 'washing_symbol'\n",
            "    display_name: 'washing_symbol'\n",
            " }"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_tyvKnBP6qD",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Preparing Tensorflow model\n",
        "1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git). This repo contains object detection API. \n",
        "2. Compiling the protos and adding folders to the os environment.\n",
        "3. Testing the model builder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIxz1GqJQA3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bd03c25-7b08-403e-a6cd-cf059817f2f3"
      },
      "source": [
        "%cd /content/CareLabelsData/\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CareLabelsData\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjcAhsxRQ5N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d46ed86-3ad0-4554-ddd5-1b92a2837930"
      },
      "source": [
        "%cd /content/CareLabelsData/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "os.environ['PYTHONPATH'] += ':/content/CareLabelsData/models/research/:/content/CareLabelsData/models/research/slim/'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CareLabelsData/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMNsrwTSJi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b84c1f58-a313-4b58-c884-0dbbce655ac3"
      },
      "source": [
        "!pip3 install tf_slim\n",
        "!python3 object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9C3L_r4Pi6m",
        "colab_type": "text"
      },
      "source": [
        "## Generating Tf record\n",
        "- Generating TFRecords files for training and testing csv's.\n",
        "- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK2unk-9LB_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7fb1520e-bb85-421e-91a5-d9a8c4c7f928"
      },
      "source": [
        "from object_detection.utils import dataset_util\n",
        "%cd /content/CareLabelsData/models/\n",
        "\n",
        "DATA_BASE_PATH = '/content/CareLabelsData/data/'\n",
        "image_dir = '/content/CareLabelsData/data/images'\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "\t\tif row_label == 'bleaching_with_chlorine_allowed':\n",
        "\t\t\t\treturn 1\n",
        "\t\telif row_label == 'chlorine_and_non_chlorine_bleach':\n",
        "\t\t\t\treturn 2\n",
        "\t\telif row_label == 'do_not_bleach':\n",
        "\t\t\t\treturn 3\n",
        "\t\telif row_label == 'do_not_dry_clean':\n",
        "\t\t\t\treturn 4\n",
        "\t\telif row_label == 'do_not_iron':\n",
        "\t\t\t\treturn 5\n",
        "\t\telif row_label == 'do_not_tumble_drying':\n",
        "\t\t\t\treturn 6\n",
        "\t\telif row_label == 'do_not_wash':\n",
        "\t\t\t\treturn 7\n",
        "\t\telif row_label == 'do_not_wet_clean':\n",
        "\t\t\t\treturn 8\n",
        "\t\telif row_label == 'drip_dry_in_the_shade':\n",
        "\t\t\t\treturn 9\n",
        "\t\telif row_label == 'drip_dry':\n",
        "\t\t\t\treturn 10\n",
        "\t\telif row_label == 'dry_clean_any_solvent':\n",
        "\t\t\t\treturn 11\n",
        "\t\telif row_label == 'dry_clean_hydrocarbon_solvent_only_hcs':\n",
        "\t\t\t\treturn 12\n",
        "\t\telif row_label == 'dry_clean_tetrachloroethylene_pce_only':\n",
        "\t\t\t\treturn 13\n",
        "\t\telif row_label == 'dry_flat_in_the_shade':\n",
        "\t\t\t\treturn 14\n",
        "\t\telif row_label == 'dry_flat':\n",
        "\t\t\t\treturn 15\n",
        "\t\telif row_label == 'dry_in_the_shade':\n",
        "\t\t\t\treturn 16\n",
        "\t\telif row_label == 'drying_symbol':\n",
        "\t\t\t\treturn 17\n",
        "\t\telif row_label == 'gentle_cleaning_with_hydrocarbon_solvents':\n",
        "\t\t\t\treturn 18\n",
        "\t\telif row_label == 'gentle_cleaning_with_pce':\n",
        "\t\t\t\treturn 19\n",
        "\t\telif row_label == 'gentle_wet_cleaning':\n",
        "\t\t\t\treturn 20\n",
        "\t\telif row_label == 'hand_wash':\n",
        "\t\t\t\treturn 21\n",
        "\t\telif row_label == 'ironing_at_high_temp':\n",
        "\t\t\t\treturn 22\n",
        "\t\telif row_label == 'ironing_at_low_temp':\n",
        "\t\t\t\treturn 23\n",
        "\t\telif row_label == 'ironing_at_med_temp':\n",
        "\t\t\t\treturn 24\n",
        "\t\telif row_label == 'ironing':\n",
        "\t\t\t\treturn 25\n",
        "\t\telif row_label == 'line_dry_in_the_shade':\n",
        "\t\t\t\treturn 26\n",
        "\t\telif row_label == 'line_dry':\n",
        "\t\t\t\treturn 27\n",
        "\t\telif row_label == 'no_steam':\n",
        "\t\t\t\treturn 28\n",
        "\t\telif row_label == 'non_chlorine_bleach_when_needed':\n",
        "\t\t\t\treturn 29\n",
        "\t\telif row_label == 'professional_cleaning':\n",
        "\t\t\t\treturn 30\n",
        "\t\telif row_label == 'professional_wet_cleaning':\n",
        "\t\t\t\treturn 31\n",
        "\t\telif row_label == 'tumble_drying_low_temps':\n",
        "\t\t\t\treturn 32\n",
        "\t\telif row_label == 'tumble_drying_normal':\n",
        "\t\t\t\treturn 33\n",
        "\t\telif row_label == 'tumble_drying':\n",
        "\t\t\t\treturn 34\n",
        "\t\telif row_label == 'very_gentle_cleaning_with_hydrocarbon_solvents':\n",
        "\t\t\t\treturn 35\n",
        "\t\telif row_label == 'very_gentle_cleaning_with_pce':\n",
        "\t\t\t\treturn 36\n",
        "\t\telif row_label == 'very_gentle_wet_cleaning':\n",
        "\t\t\t\treturn 37\n",
        "\t\telif row_label == 'wash_at_or_below_30_mild_fine_wash':\n",
        "\t\t\t\treturn 38\n",
        "\t\telif row_label == 'wash_at_or_below_30_very_mild_fine_wash':\n",
        "\t\t\t\treturn 39\n",
        "\t\telif row_label == 'wash_at_or_below_30':\n",
        "\t\t\t\treturn 40\n",
        "\t\telif row_label == 'wash_at_or_below_40_mild_fine_wash':\n",
        "\t\t\t\treturn 41\n",
        "\t\telif row_label == 'wash_at_or_below_40_very_mild_fine_wash':\n",
        "\t\t\t\treturn 42\n",
        "\t\telif row_label == 'wash_at_or_below_40':\n",
        "\t\t\t\treturn 43\n",
        "\t\telif row_label == 'wash_at_or_below_50_mild_fine_wash':\n",
        "\t\t\t\treturn 44\n",
        "\t\telif row_label == 'wash_at_or_below_50':\n",
        "\t\t\t\treturn 45\n",
        "\t\telif row_label == 'wash_at_or_below_60_mild_fine_wash':\n",
        "\t\t\t\treturn 46\n",
        "\t\telif row_label == 'wash_at_or_below_60':\n",
        "\t\t\t\treturn 47\n",
        "\t\telif row_label == 'wash_at_or_below_70':\n",
        "\t\t\t\treturn 48\n",
        "\t\telif row_label == 'wash_at_or_below_90':\n",
        "\t\t\t\treturn 49\n",
        "\t\telif row_label == 'washing_symbol':\n",
        "\t\t\t\treturn 50\t\t\t\n",
        "\t\telse:\n",
        "\t\t\t\t0\n",
        "\n",
        "def split(df, group):\n",
        "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
        "\t\tgb = df.groupby(group)\n",
        "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(os.path.splitext(group.filename)[0])), 'rb') as fid:\n",
        "\t\t\t\tencoded_jpg = fid.read()\n",
        "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\t\timage = Image.open(encoded_jpg_io)\n",
        "\t\twidth, height = image.size\n",
        "\n",
        "\t\tfilename = group.filename.encode('utf8')\n",
        "\t\txmins = []\n",
        "\t\txmaxs = []\n",
        "\t\tymins = []\n",
        "\t\tymaxs = []\n",
        "\t\tclasses_text = []\n",
        "\t\tclasses = []\n",
        "\n",
        "\t\tfor index, row in group.object.iterrows():\n",
        "\t\t\t\txmins.append(row['xmin'] / width)\n",
        "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
        "\t\t\t\tymins.append(row['ymin'] / height)\n",
        "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
        "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
        "\n",
        "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t\t\t'image/filename': dataset_util.bytes_feature(os.path.splitext(filename)[0]),\n",
        "\t\t\t\t'image/source_id': dataset_util.bytes_feature(os.path.splitext(filename)[0]),\n",
        "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t\t\t'image/format': dataset_util.bytes_feature(b'jpg'),\n",
        "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t\t}))\n",
        "\t\treturn tf_example\n",
        "\n",
        "for csv in ['train_labels', 'test_labels']:\n",
        "  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n",
        "  path = os.path.join(image_dir)\n",
        "  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "      tf_example = create_tf_example(group, path)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "    \n",
        "  writer.close()\n",
        "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
        "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CareLabelsData/models\n",
            "Successfully created the TFRecords: /content/CareLabelsData/data/train_labels.record\n",
            "Successfully created the TFRecords: /content/CareLabelsData/data/test_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1zRJducWs-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "360eb600-ef6f-46c2-f893-6c61140803d8"
      },
      "source": [
        "!ls -lX /content/CareLabelsData/data/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 66792\n",
            "drwxr-xr-x 2 root root     4096 Sep 12 12:41 images\n",
            "drwxr-xr-x 2 root root     4096 Sep 12 12:41 test_labels\n",
            "drwxr-xr-x 2 root root     4096 Sep 12 12:41 train_labels\n",
            "-rw-r--r-- 1 root root      929 Sep 12 12:42 test_labels.csv\n",
            "-rw-r--r-- 1 root root    32735 Sep 12 12:42 train_labels.csv\n",
            "-rw-r--r-- 1 root root     5092 Sep 12 12:42 label_map.pbtxt\n",
            "-rw-r--r-- 1 root root  2006675 Sep 12 12:42 test_labels.record\n",
            "-rw-r--r-- 1 root root 66329466 Sep 12 12:42 train_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMckMSJqFMyc",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the Base Model\n",
        "1. Downloading the selected model and extracting its content.\n",
        "2. Creating a directory to save model while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvN9Cw65FQzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "078431dd-ae0a-4572-c3a1-4e1872519c0f"
      },
      "source": [
        "%cd /content/CareLabelsData/models/research\n",
        "\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "fine_tune_dir = '/content/CareLabelsData/models/research/pretrained_model'\n",
        "\n",
        "#checks if already downloaded\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(fine_tune_dir)):\n",
        "    shutil.rmtree(fine_tune_dir)\n",
        "os.rename(MODEL, fine_tune_dir)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CareLabelsData/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjXKVMmFk47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "496f4f77-4a0a-40ac-9e0d-bd955a447380"
      },
      "source": [
        "!echo {fine_tune_dir}\n",
        "!ls -alh {fine_tune_dir}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CareLabelsData/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 24 root   root  4.0K Sep 12 12:43 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnjQgJZiGAcA",
        "colab_type": "text"
      },
      "source": [
        "## Configuring the Training Pipeline\n",
        "1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n",
        "2. Adding some Image augmentation.\n",
        "3. Creating a directory to save the model at each checkpoint while training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az14XVo31Ujp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49584f42-6e2c-47d0-f63d-008feec2fda7"
      },
      "source": [
        "CONFIG_BASE = \"/content/CareLabelsData/models/research/object_detection/samples/configs/\"\n",
        "\n",
        "model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n",
        "model_pipline"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/CareLabelsData/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfsl5CsDGY3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3330652-e553-4a21-816a-f605bb4b7536"
      },
      "source": [
        "%%writefile {model_pipline}\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 50 # number of classes\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    # all images will be resized to height and width parametrs\n",
        "    image_resizer { \n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: true # to counter over fitting\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000 \n",
        "        iou_threshold: 0.95\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        \n",
        "        #there are some images with more than one up to 3.\n",
        "        #5 for future proof\n",
        "        max_detections_per_class: 5\n",
        "        #probably overkill, max 12 labels in one image \n",
        "        max_total_detections: 16\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 16 # training batch size\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.003\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "\n",
        "  #the path to the pretrained model. \n",
        "  fine_tune_checkpoint: \"/content/CareLabelsData/models/research/pretrained_model/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  num_steps: 10000 \n",
        "  \n",
        "\n",
        "  # data augmentaion will help the model generalize but training time will increase greatly  \n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_adjust_contrast {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/CareLabelsData/data/train_labels.record\"    #path to the training TFRecord\n",
        "  }\n",
        "  label_map_path: \"/content/CareLabelsData/data/label_map.pbtxt\"  #path to the label map \n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 3  # the number of images in your \"testing\" data\n",
        "  num_visualizations: 3  # the number of images to disply in Tensorboard\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  #max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/CareLabelsData/data/test_labels.record\"    #path to the testing TFRecord\n",
        "  }\n",
        "  label_map_path: \"/content/CareLabelsData/data/label_map.pbtxt\"  #path to the label map \n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/CareLabelsData/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXXZLVEG8sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'# dir where model will be saved at each checkpoint\n",
        "\n",
        "# remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vAGvftxHu8K",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard\n",
        "1. Downlaoding and Unzipping\n",
        "2. Creating a link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ucxlc5HxHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "afb539bc-7981-4cc4-ec7e-1e1947adba16"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-12 12:43:18--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.205.91.57, 52.201.131.65, 52.2.226.158, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.205.91.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  17.8MB/s    in 0.7s    \n",
            "\n",
            "2020-09-12 12:43:19 (17.8 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9ufxr7IAdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idsi9zyNIIsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69365436-58a5-4096-ff3a-5da6e12b9d56"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://f5e584d64cdf.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuJcAPZFIfu7",
        "colab_type": "text"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnKt6g0_IgOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd2803e2-220f-46c0-f66c-31fc7d1317ce"
      },
      "source": [
        "!python3 /content/CareLabelsData/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={model_pipline}\\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0912 12:43:29.566325 140357349037952 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0912 12:43:29.566520 140357349037952 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0912 12:43:29.566605 140357349037952 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0912 12:43:29.566694 140357349037952 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0912 12:43:29.566774 140357349037952 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0912 12:43:29.566874 140357349037952 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0912 12:43:29.567071 140357349037952 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa7124642e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0912 12:43:29.567471 140357349037952 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa7124642e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa712462d90>) includes params argument, but params are not passed to Estimator.\n",
            "W0912 12:43:29.567698 140357349037952 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa712462d90>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0912 12:43:29.568436 140357349037952 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0912 12:43:29.568612 140357349037952 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0912 12:43:29.568843 140357349037952 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0912 12:43:29.580298 140357349037952 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0912 12:43:29.621409 140357349037952 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/CareLabelsData/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0912 12:43:29.626209 140357349037952 deprecation.py:323] From /content/CareLabelsData/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/CareLabelsData/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0912 12:43:29.645051 140357349037952 deprecation.py:323] From /content/CareLabelsData/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fa711f66e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0912 12:43:29.675670 140357349037952 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fa711f66e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fa731bbbd08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0912 12:43:29.857437 140357349037952 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fa731bbbd08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/CareLabelsData/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0912 12:43:29.862930 140357349037952 deprecation.py:323] From /content/CareLabelsData/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/CareLabelsData/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0912 12:43:29.869785 140357349037952 deprecation.py:323] From /content/CareLabelsData/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/CareLabelsData/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0912 12:43:29.965571 140357349037952 deprecation.py:323] From /content/CareLabelsData/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/CareLabelsData/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0912 12:43:30.763864 140357349037952 deprecation.py:323] From /content/CareLabelsData/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0912 12:43:31.188285 140357349037952 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0912 12:43:31.423601 140357349037952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0912 12:43:33.746744 140357349037952 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0912 12:43:33.933520 140357349037952 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0912 12:43:33.968293 140357349037952 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0912 12:43:34.003022 140357349037952 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0912 12:43:34.040376 140357349037952 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0912 12:43:34.074670 140357349037952 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0912 12:43:38.543083 140357349037952 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0912 12:43:44.085738 140357349037952 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0912 12:43:44.086993 140357349037952 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0912 12:43:47.219138 140357349037952 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-12 12:43:47.231615: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2020-09-12 12:43:47.231862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3133d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-12 12:43:47.231897: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-09-12 12:43:47.236381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-09-12 12:43:47.406076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-12 12:43:47.406753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3132f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-12 12:43:47.406784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-09-12 12:43:47.407872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-12 12:43:47.408401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-12 12:43:47.408789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-12 12:43:47.655267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-12 12:43:47.780004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-12 12:43:47.821830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-12 12:43:48.076750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-12 12:43:48.096994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-12 12:43:48.592732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-12 12:43:48.592947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-12 12:43:48.593586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-12 12:43:48.594091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-12 12:43:48.597052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-12 12:43:48.598387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-12 12:43:48.598416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-12 12:43:48.598427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-12 12:43:48.599426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-12 12:43:48.600044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-12 12:43:48.600547: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-09-12 12:43:48.600588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0912 12:43:59.607475 140357349037952 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0912 12:43:59.924028 140357349037952 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0912 12:44:08.260089 140357349037952 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-09-12 12:44:24.558811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-12 12:44:28.900174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 178.97118, step = 0\n",
            "I0912 12:44:31.177748 140357349037952 basic_session_run_hooks.py:262] loss = 178.97118, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.46089\n",
            "I0912 12:45:39.628603 140357349037952 basic_session_run_hooks.py:692] global_step/sec: 1.46089\n",
            "INFO:tensorflow:loss = 16.794903, step = 100 (68.452 sec)\n",
            "I0912 12:45:39.629764 140357349037952 basic_session_run_hooks.py:260] loss = 16.794903, step = 100 (68.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58217\n",
            "I0912 12:46:42.832849 140357349037952 basic_session_run_hooks.py:692] global_step/sec: 1.58217\n",
            "INFO:tensorflow:loss = 12.957102, step = 200 (63.204 sec)\n",
            "I0912 12:46:42.834062 140357349037952 basic_session_run_hooks.py:260] loss = 12.957102, step = 200 (63.204 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPN8liiQc7Ue",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Exporting trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upwUdom0lTub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_directory = '/content/CareLabelsData/models/research/fine_tuned_model'# exported model location\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "!python /content/CareLabelsData/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={model_pipline} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuxDnGPM_JPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(output_directory + '/frozen_inference_graph.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTkkaGq5BpYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(DATA_BASE_PATH + '/label_map.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}