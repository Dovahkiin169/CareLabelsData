{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weapon_detection_BL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "A_tyvKnBP6qD",
        "t9C3L_r4Pi6m",
        "xMckMSJqFMyc",
        "8vAGvftxHu8K",
        "IuJcAPZFIfu7",
        "RPN8liiQc7Ue"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlXJ2yIV8e7",
        "colab_type": "text"
      },
      "source": [
        "## Choosing a pre training model\n",
        "The model used for this project is `ssd_mobilenet_v2_coco`.\n",
        "Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        "\n",
        "Because the interestes of this project is to interfere on real time video, i am chosing a model that has a high inference speed `(ms)` with relativly high `mAP` on COCO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3_Ns54i3HgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6f7eed7f-9edd-4914-961e-66ac9355e465"
      },
      "source": [
        "\n",
        "%tensorflow_version 1.x # Select module of the tensorflow\n",
        "# Some models to train on\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "    }\n",
        "}\n",
        "\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "# I chose ssd_mobilenet_v2 for this project, you could choose any\n",
        "selected_model = 'ssd_mobilenet_v2'\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x # Select module of the tensorflow`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3Zm042QGJy",
        "colab_type": "text"
      },
      "source": [
        "## Installing Required Packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68StUELaQPS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "ed1244e0-0650-4851-cb85-24a7a5fa2087"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -qq pycocotools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144579 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERyocH9U-o2Y",
        "colab_type": "text"
      },
      "source": [
        "## General imports\n",
        "Other Imports will be done after downloading some packages later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEVLeKXh-s23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import cv2 \n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import io\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from PIL import Image\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "import shutil\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8QeHvX6gpmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9884155e-8032-48e8-909a-1b44b510ee87"
      },
      "source": [
        "#we need tenorflow v 1.15.0, object detection API is removed from tf v 2.0+\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOcbTFEiPBKA",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Orgniazing Images and Annotations\n",
        "1. Downloading the images and annotations from the [source](https://sci2s.ugr.es/weapons-detection)  and unziping them\n",
        "2. Creating a directory `(data)` to save some data such as; images, annotation, csv, etc...\n",
        "3. Creating two directories; for the training and testing labels (not the images)\n",
        "4. Randomly splitting our labels into 80% training and 20% testing and moving the splits to their directories: `(train_labels)` & `(test_labels)` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QY-CyUQwyZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates a directory for the whole project\n",
        "!mkdir gun_detection"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebLK0eX_ezhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ae0d4e8c-43b9-4fea-9614-10af9344ee9f"
      },
      "source": [
        "!git clone https://github.com/Dovahkiin169/CareLabelsData.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CareLabelsData'...\n",
            "remote: Enumerating objects: 136, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 568 (delta 116), reused 117 (delta 97), pack-reused 432\u001b[K\n",
            "Receiving objects: 100% (568/568), 190.25 MiB | 13.79 MiB/s, done.\n",
            "Resolving deltas: 100% (328/328), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHPQQmhm7RLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2015306d-6a8c-4b14-c954-64d2b5944e31"
      },
      "source": [
        "cd gun_detection"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JxCdR-c8yGp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOfuwfPrPSMz",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Images and Labels\n",
        "1. Converting the annotations from xml files to two csv files for each `train_labels/` and `train_labels/`.\n",
        "2. Creating a pbtxt file that specifies the number of class (one class in this case)\n",
        "3. Checking if the annotations for each object are placed within the range of the image width and height."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBHBFpWyEIDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f2d69709-90d0-48a3-c153-6ed3c0d4ff7a"
      },
      "source": [
        "\n",
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "\n",
        "#converts the annotations/labels into one csv file for each training and testing labels\n",
        "#creats label_map.pbtxt file\n",
        "\n",
        "%cd /content/gun_detection/data\n",
        "\n",
        "\n",
        "# images extension\n",
        "images_extension = 'jpg'\n",
        "\n",
        "# takes the path of a directory that contains xml files and converts\n",
        "#  them to one csv file.\n",
        "\n",
        "# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n",
        "# note: if the xml file contains more than one box/label, it will create more than one row for the same image. each row contains the info for an individual box. \n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text + '.' + images_extension,\n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "# Creating the `label_map.pbtxt` file\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "#creats a pbtxt file the has the class names.\n",
        "for i, class_name in enumerate(classes):\n",
        "    # display_name is optional.\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: '{1}'\\n }}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/data\n",
            "Successfully converted train_labels xml to csv.\n",
            "Successfully converted test_labels xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtfjZcD-CCdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8d16c30-7a8f-42b9-c9d5-a4ed577d08c9"
      },
      "source": [
        "#checking the pbtxt file\n",
        "!cat label_map.pbtxt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "    id: 1\n",
            "    name: 'bleaching_with_chlorine_allowed'\n",
            "    display_name: 'bleaching_with_chlorine_allowed'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 2\n",
            "    name: 'chlorine_and_non_chlorine_bleach'\n",
            "    display_name: 'chlorine_and_non_chlorine_bleach'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 3\n",
            "    name: 'do_not_bleach'\n",
            "    display_name: 'do_not_bleach'\n",
            " }\n",
            "\n",
            " item {\n",
            "    id: 4\n",
            "    name: 'do_not_dry_clean'\n",
            "    display_name: 'do_not_dry_clean'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 5\n",
            "    name: 'do_not_iron'\n",
            "    display_name: 'do_not_iron'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 6\n",
            "    name: 'do_not_tumble_drying'\n",
            "    display_name: 'do_not_tumble_drying'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 7\n",
            "    name: 'do_not_wash'\n",
            "    display_name: 'do_not_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 8\n",
            "    name: 'do_not_wet_clean'\n",
            "    display_name: 'do_not_wet_clean'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 9\n",
            "    name: 'drip_dry_in_the_shade'\n",
            "    display_name: 'drip_dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 10\n",
            "    name: 'drip_dry'\n",
            "    display_name: 'drip_dry'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 11\n",
            "    name: 'dry_clean_any_solvent'\n",
            "    display_name: 'dry_clean_any_solvent'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 12\n",
            "    name: 'dry_clean_hydrocarbon_solvent_only_hcs'\n",
            "    display_name: 'dry_clean_hydrocarbon_solvent_only_hcs'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 13\n",
            "    name: 'dry_clean_tetrachloroethylene_pce_only'\n",
            "    display_name: 'dry_clean_tetrachloroethylene_pce_only'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 14\n",
            "    name: 'dry_flat_in_the_shade'\n",
            "    display_name: 'dry_flat_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 15\n",
            "    name: 'dry_flat'\n",
            "    display_name: 'dry_flat'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 16\n",
            "    name: 'dry_in_the_shade'\n",
            "    display_name: 'dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 17\n",
            "    name: 'drying_symbol'\n",
            "    display_name: 'drying_symbol'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 18\n",
            "    name: 'gentle_cleaning_with_hydrocarbon_solvents'\n",
            "    display_name: 'gentle_cleaning_with_hydrocarbon_solvents'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 19\n",
            "    name: 'gentle_cleaning_with_pce'\n",
            "    display_name: 'gentle_cleaning_with_pce'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 20\n",
            "    name: 'gentle_wet_cleaning'\n",
            "    display_name: 'gentle_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 21\n",
            "    name: 'hand_wash'\n",
            "    display_name: 'hand_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 22\n",
            "    name: 'ironing_at_high_temp'\n",
            "    display_name: 'ironing_at_high_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 23\n",
            "    name: 'ironing_at_low_temp'\n",
            "    display_name: 'ironing_at_low_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 24\n",
            "    name: 'ironing_at_med_temp'\n",
            "    display_name: 'ironing_at_med_temp'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 25\n",
            "    name: 'ironing'\n",
            "    display_name: 'ironing'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 26\n",
            "    name: 'line_dry_in_the_shade'\n",
            "    display_name: 'line_dry_in_the_shade'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 27\n",
            "    name: 'line_dry'\n",
            "    display_name: 'line_dry'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 28\n",
            "    name: 'no_steam'\n",
            "    display_name: 'no_steam'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 29\n",
            "    name: 'non_chlorine_bleach_when_needed'\n",
            "    display_name: 'non_chlorine_bleach_when_needed'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 30\n",
            "    name: 'professional_cleaning'\n",
            "    display_name: 'professional_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 31\n",
            "    name: 'professional_wet_cleaning'\n",
            "    display_name: 'professional_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 32\n",
            "    name: 'tumble_drying_low_temps'\n",
            "    display_name: 'tumble_drying_low_temps'\n",
            " }\n",
            " \n",
            "  item {\n",
            "    id: 33\n",
            "    name: 'tumble_drying_normal'\n",
            "    display_name: 'tumble_drying_normal'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 34\n",
            "    name: 'tumble_drying'\n",
            "    display_name: 'tumble_drying'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 35\n",
            "    name: 'very_gentle_cleaning_with_hydrocarbon_solvents'\n",
            "    display_name: 'very_gentle_cleaning_with_hydrocarbon_solvents'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 36\n",
            "    name: 'very_gentle_cleaning_with_pce'\n",
            "    display_name: 'very_gentle_cleaning_with_pce'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 37\n",
            "    name: 'very_gentle_wet_cleaning'\n",
            "    display_name: 'very_gentle_wet_cleaning'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 38\n",
            "    name: 'wash_at_or_below_30_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_30_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 39\n",
            "    name: 'wash_at_or_below_30_very_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_30_very_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 40\n",
            "    name: 'wash_at_or_below_30'\n",
            "    display_name: 'wash_at_or_below_30'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 41\n",
            "    name: 'wash_at_or_below_40_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_40_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 42\n",
            "    name: 'wash_at_or_below_40_very_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_40_very_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 43\n",
            "    name: 'wash_at_or_below_40'\n",
            "    display_name: 'wash_at_or_below_40'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 44\n",
            "    name: 'wash_at_or_below_50_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_50_mild_fine_wash'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 45\n",
            "    name: 'wash_at_or_below_50'\n",
            "    display_name: 'wash_at_or_below_50'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 46\n",
            "    name: 'wash_at_or_below_60_mild_fine_wash'\n",
            "    display_name: 'wash_at_or_below_60_mild_fine_wash'\n",
            " }\n",
            "\n",
            "   item {\n",
            "    id: 47\n",
            "    name: 'wash_at_or_below_60'\n",
            "    display_name: 'wash_at_or_below_60'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 48\n",
            "    name: 'wash_at_or_below_70'\n",
            "    display_name: 'wash_at_or_below_70'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 49\n",
            "    name: 'wash_at_or_below_90'\n",
            "    display_name: 'wash_at_or_below_90'\n",
            " }\n",
            "\n",
            "  item {\n",
            "    id: 50\n",
            "    name: 'washing_symbol'\n",
            "    display_name: 'washing_symbol'\n",
            " }"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_tyvKnBP6qD",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Preparing Tensorflow model\n",
        "1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interseted in. \n",
        "2. Compiling the protos and adding folders to the os environment.\n",
        "3. Testing the model builder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIxz1GqJQA3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72e9a609-9612-4819-8411-64579ea3c0ea"
      },
      "source": [
        "# Downlaods Tenorflow\n",
        "%cd /content/gun_detection/\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjcAhsxRQ5N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52ecb0b0-f3a2-4c31-f649-a784c9caeffc"
      },
      "source": [
        "%cd /content/gun_detection/models/research\n",
        "#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
        "os.environ['PYTHONPATH'] += ':/content/gun_detection/models/research/:/content/gun_detection/models/research/slim/'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMNsrwTSJi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0f4b6551-7d77-408e-da6d-8e2ec283be06"
      },
      "source": [
        "# testing the model builder\n",
        "!pip3 install tf_slim\n",
        "!python3 object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9C3L_r4Pi6m",
        "colab_type": "text"
      },
      "source": [
        "## Generating Tf record\n",
        "- Generating two TFRecords files for the training and testing CSVs.\n",
        "- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage. Instead of loading the full data into memory, Tenorflow breaks the data into batches using these TFRecords automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK2unk-9LB_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b854627-4826-4f0b-ea34-a07b317b0156"
      },
      "source": [
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "\n",
        "# converts the csv files for training and testing data to two TFRecords files.\n",
        "# places the output in the same directory as the input\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "%cd /content/gun_detection/models/\n",
        "\n",
        "DATA_BASE_PATH = '/content/gun_detection/data/'\n",
        "image_dir = '/content/gun_detection/data/images'\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "\t\tif row_label == 'bleaching_with_chlorine_allowed':\n",
        "\t\t\t\treturn 1\n",
        "\t\telif row_label == 'chlorine_and_non_chlorine_bleach':\n",
        "\t\t\t\treturn 2\n",
        "\t\telif row_label == 'do_not_bleach':\n",
        "\t\t\t\treturn 3\n",
        "\t\telif row_label == 'do_not_dry_clean':\n",
        "\t\t\t\treturn 4\n",
        "\t\telif row_label == 'do_not_iron':\n",
        "\t\t\t\treturn 5\n",
        "\t\telif row_label == 'do_not_tumble_drying':\n",
        "\t\t\t\treturn 6\n",
        "\t\telif row_label == 'do_not_wash':\n",
        "\t\t\t\treturn 7\n",
        "\t\telif row_label == 'do_not_wet_clean':\n",
        "\t\t\t\treturn 8\n",
        "\t\telif row_label == 'drip_dry_in_the_shade':\n",
        "\t\t\t\treturn 9\n",
        "\t\telif row_label == 'drip_dry':\n",
        "\t\t\t\treturn 10\n",
        "\t\telif row_label == 'dry_clean_any_solvent':\n",
        "\t\t\t\treturn 11\n",
        "\t\telif row_label == 'dry_clean_hydrocarbon_solvent_only_hcs':\n",
        "\t\t\t\treturn 12\n",
        "\t\telif row_label == 'dry_clean_tetrachloroethylene_pce_only':\n",
        "\t\t\t\treturn 13\n",
        "\t\telif row_label == 'dry_flat_in_the_shade':\n",
        "\t\t\t\treturn 14\n",
        "\t\telif row_label == 'dry_flat':\n",
        "\t\t\t\treturn 15\n",
        "\t\telif row_label == 'dry_in_the_shade':\n",
        "\t\t\t\treturn 16\n",
        "\t\telif row_label == 'drying_symbol':\n",
        "\t\t\t\treturn 17\n",
        "\t\telif row_label == 'gentle_cleaning_with_hydrocarbon_solvents':\n",
        "\t\t\t\treturn 18\n",
        "\t\telif row_label == 'gentle_cleaning_with_pce':\n",
        "\t\t\t\treturn 19\n",
        "\t\telif row_label == 'gentle_wet_cleaning':\n",
        "\t\t\t\treturn 20\n",
        "\t\telif row_label == 'hand_wash':\n",
        "\t\t\t\treturn 21\n",
        "\t\telif row_label == 'ironing_at_high_temp':\n",
        "\t\t\t\treturn 22\n",
        "\t\telif row_label == 'ironing_at_low_temp':\n",
        "\t\t\t\treturn 23\n",
        "\t\telif row_label == 'ironing_at_med_temp':\n",
        "\t\t\t\treturn 24\n",
        "\t\telif row_label == 'ironing':\n",
        "\t\t\t\treturn 25\n",
        "\t\telif row_label == 'line_dry_in_the_shade':\n",
        "\t\t\t\treturn 26\n",
        "\t\telif row_label == 'line_dry':\n",
        "\t\t\t\treturn 27\n",
        "\t\telif row_label == 'no_steam':\n",
        "\t\t\t\treturn 28\n",
        "\t\telif row_label == 'non_chlorine_bleach_when_needed':\n",
        "\t\t\t\treturn 29\n",
        "\t\telif row_label == 'professional_cleaning':\n",
        "\t\t\t\treturn 30\n",
        "\t\telif row_label == 'professional_wet_cleaning':\n",
        "\t\t\t\treturn 31\n",
        "\t\telif row_label == 'tumble_drying_low_temps':\n",
        "\t\t\t\treturn 32\n",
        "\t\telif row_label == 'tumble_drying_normal':\n",
        "\t\t\t\treturn 33\n",
        "\t\telif row_label == 'tumble_drying':\n",
        "\t\t\t\treturn 34\n",
        "\t\telif row_label == 'very_gentle_cleaning_with_hydrocarbon_solvents':\n",
        "\t\t\t\treturn 35\n",
        "\t\telif row_label == 'very_gentle_cleaning_with_pce':\n",
        "\t\t\t\treturn 36\n",
        "\t\telif row_label == 'very_gentle_wet_cleaning':\n",
        "\t\t\t\treturn 37\n",
        "\t\telif row_label == 'wash_at_or_below_30_mild_fine_wash':\n",
        "\t\t\t\treturn 38\n",
        "\t\telif row_label == 'wash_at_or_below_30_very_mild_fine_wash':\n",
        "\t\t\t\treturn 39\n",
        "\t\telif row_label == 'wash_at_or_below_30':\n",
        "\t\t\t\treturn 40\n",
        "\t\telif row_label == 'wash_at_or_below_40_mild_fine_wash':\n",
        "\t\t\t\treturn 41\n",
        "\t\telif row_label == 'wash_at_or_below_40_very_mild_fine_wash':\n",
        "\t\t\t\treturn 42\n",
        "\t\telif row_label == 'wash_at_or_below_40':\n",
        "\t\t\t\treturn 43\n",
        "\t\telif row_label == 'wash_at_or_below_50_mild_fine_wash':\n",
        "\t\t\t\treturn 44\n",
        "\t\telif row_label == 'wash_at_or_below_50':\n",
        "\t\t\t\treturn 45\n",
        "\t\telif row_label == 'wash_at_or_below_60_mild_fine_wash':\n",
        "\t\t\t\treturn 46\n",
        "\t\telif row_label == 'wash_at_or_below_60':\n",
        "\t\t\t\treturn 47\n",
        "\t\telif row_label == 'wash_at_or_below_70':\n",
        "\t\t\t\treturn 48\n",
        "\t\telif row_label == 'wash_at_or_below_90':\n",
        "\t\t\t\treturn 49\n",
        "\t\telif row_label == 'washing_symbol':\n",
        "\t\t\t\treturn 50\t\t\t\n",
        "\t\telse:\n",
        "\t\t\t\t0\n",
        "\n",
        "def split(df, group):\n",
        "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
        "\t\tgb = df.groupby(group)\n",
        "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(os.path.splitext(group.filename)[0])), 'rb') as fid:\n",
        "\t\t\t\tencoded_jpg = fid.read()\n",
        "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\t\timage = Image.open(encoded_jpg_io)\n",
        "\t\twidth, height = image.size\n",
        "\n",
        "\t\tfilename = group.filename.encode('utf8')\n",
        "\t\t#image_format = 'jpg'\n",
        "\t\txmins = []\n",
        "\t\txmaxs = []\n",
        "\t\tymins = []\n",
        "\t\tymaxs = []\n",
        "\t\tclasses_text = []\n",
        "\t\tclasses = []\n",
        "\n",
        "\t\tfor index, row in group.object.iterrows():\n",
        "\t\t\t\txmins.append(row['xmin'] / width)\n",
        "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
        "\t\t\t\tymins.append(row['ymin'] / height)\n",
        "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
        "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
        "\n",
        "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t\t\t'image/filename': dataset_util.bytes_feature(os.path.splitext(filename)[0]),\n",
        "\t\t\t\t'image/source_id': dataset_util.bytes_feature(os.path.splitext(filename)[0]),\n",
        "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t\t\t'image/format': dataset_util.bytes_feature(b'jpg'),\n",
        "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t\t}))\n",
        "\t\tprint(classes)\n",
        "\t\treturn tf_example\n",
        "\n",
        "for csv in ['train_labels', 'test_labels']:\n",
        "  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n",
        "  path = os.path.join(image_dir)\n",
        "  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "      tf_example = create_tf_example(group, path)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "    \n",
        "  writer.close()\n",
        "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
        "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models\n",
            "[43, 3, 32, 24, 4]\n",
            "[38, 38, 43, 3, 32, 24, 4]\n",
            "[43, 3, 6, 24, 4]\n",
            "[40, 3, 6, 24, 4]\n",
            "[40, 40, 3, 3, 40, 3, 6, 6, 23, 23, 13, 13, 6]\n",
            "[40, 3, 6, 23, 4]\n",
            "[38, 3, 6, 23, 4]\n",
            "[43, 3, 32, 24, 4]\n",
            "[40, 3, 32, 24, 4]\n",
            "[43, 3, 32, 23, 4]\n",
            "[40, 3, 6, 23, 4]\n",
            "[41, 3, 6, 24, 13]\n",
            "[38, 38, 14, 3, 3, 6, 6, 23, 23, 13, 13]\n",
            "[38, 3, 6, 23, 4]\n",
            "[43, 3, 32, 24, 4]\n",
            "[23, 13, 32]\n",
            "[43, 3, 6, 24, 13, 27]\n",
            "[43, 24, 4, 3, 6]\n",
            "[43, 3, 32, 24, 4]\n",
            "[5, 32, 38, 4, 3]\n",
            "[21, 6, 15, 24, 3, 4]\n",
            "[23, 40, 3, 6, 13]\n",
            "[43, 3, 32, 23, 13]\n",
            "[38, 3, 6, 23, 4]\n",
            "[38, 38, 14, 3, 3, 6, 6, 23, 23, 13, 13]\n",
            "[41, 41, 3, 3, 6, 6, 24, 24, 13, 13]\n",
            "[43, 3, 32, 24, 4]\n",
            "[41, 3, 24, 13, 6]\n",
            "[40, 3, 6, 27, 24, 4]\n",
            "[40, 3, 6, 24, 4]\n",
            "[43, 3, 32, 24, 4, 40]\n",
            "[42, 3, 6, 23, 4]\n",
            "[40, 40, 3, 3, 32, 32, 24, 24, 13, 13]\n",
            "[43, 3, 32, 24, 4, 40, 40]\n",
            "[7, 3, 23, 6, 13]\n",
            "[21, 3, 24, 4, 6, 15]\n",
            "[40, 40, 40, 29, 29, 29, 32, 32, 32, 23, 23, 23]\n",
            "[40, 3, 6, 23, 23]\n",
            "[40, 40, 40, 3, 3, 3, 3, 6, 6, 6, 23, 23, 13, 13]\n",
            "[7, 3, 5, 6, 19]\n",
            "[21, 6, 15, 24, 3, 4]\n",
            "[40, 3, 24, 27, 4, 6]\n",
            "[43, 3, 32, 24, 4]\n",
            "[43, 3, 6, 24, 4, 40]\n",
            "[21, 23, 3, 6]\n",
            "[40, 43, 3, 32, 24, 4]\n",
            "[38, 3, 3, 6, 5, 5, 4]\n",
            "[43, 3, 6, 24, 13, 27]\n",
            "[21, 23, 3, 6, 13]\n",
            "[43, 3, 6, 24, 13, 27]\n",
            "[43, 43, 3, 3, 6, 6, 27, 27, 24, 24, 4, 4, 4]\n",
            "[38, 33, 24, 3, 4]\n",
            "[38, 38, 3, 3, 6, 6, 24, 24, 6, 13, 13]\n",
            "[43, 3, 32, 24, 4]\n",
            "[43, 3, 32, 24, 4, 40]\n",
            "[43, 3, 6, 24, 24, 27]\n",
            "[40, 3, 6, 27, 24, 4]\n",
            "[38, 3, 6, 23, 4]\n",
            "[40, 40, 43, 3, 32, 24, 4]\n",
            "[43, 3, 32, 24, 4]\n",
            "[39, 3, 23, 15, 4, 4]\n",
            "[40, 3, 24, 27, 4, 6]\n",
            "[38, 3, 6, 24, 15, 13]\n",
            "[38, 3, 6, 23, 4]\n",
            "[40, 43, 3, 32, 24, 4]\n",
            "[40, 3, 6, 23, 4]\n",
            "[4, 43, 3, 32, 24, 4]\n",
            "[41, 3, 6, 24, 4]\n",
            "[40, 3, 3, 15, 6]\n",
            "[40, 3, 6, 27, 24, 4]\n",
            "[3, 6, 23, 4]\n",
            "[21, 3, 23, 13, 6]\n",
            "[40, 3, 6, 15, 23, 4]\n",
            "[21, 3, 6, 23, 13]\n",
            "[40, 3, 6, 27, 24, 4]\n",
            "[7, 3, 23, 13, 6]\n",
            "[43, 3, 32, 23, 4, 40]\n",
            "[40, 40, 3, 3, 6, 6, 23, 23, 4, 4]\n",
            "[40, 23, 13, 3, 6]\n",
            "[40, 40, 3, 3, 6, 6, 23, 23, 4, 4]\n",
            "[40, 3, 6, 23, 4]\n",
            "[40, 3, 6, 23, 4]\n",
            "[21, 21, 3, 3, 6, 6, 6, 5, 5, 4, 4]\n",
            "[38, 3, 6, 23, 13]\n",
            "[38, 38, 3, 3, 6, 6, 6, 24, 24, 19, 19]\n",
            "[41, 3, 32, 24, 4]\n",
            "[15, 13]\n",
            "[41, 3, 32, 23, 4]\n",
            "[15, 13]\n",
            "[40, 3, 15, 5, 4]\n",
            "[40, 3, 24, 13]\n",
            "[41, 3, 6, 23, 4]\n",
            "[38, 3, 6, 5, 19]\n",
            "[38, 3, 6, 5, 19]\n",
            "[7, 3, 6, 5, 4]\n",
            "[7, 3, 6, 5, 4]\n",
            "[40, 3, 15, 5, 4]\n",
            "[40, 3, 24, 12, 27, 4, 15]\n",
            "Successfully created the TFRecords: /content/gun_detection/data/train_labels.record\n",
            "[40, 3, 6, 27, 24, 6]\n",
            "[40, 3, 15, 23, 4]\n",
            "[40, 3, 6, 15, 23, 4]\n",
            "Successfully created the TFRecords: /content/gun_detection/data/test_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1zRJducWs-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8f4a10fd-d6b2-469d-d7b3-6e55443fc27f"
      },
      "source": [
        "# TFRecords are created\n",
        "!ls -lX /content/gun_detection/data/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 66792\n",
            "drwxr-xr-x 2 root root     4096 Sep 11 15:30 images\n",
            "drwxr-xr-x 2 root root     4096 Sep 11 15:30 test_labels\n",
            "drwxr-xr-x 2 root root     4096 Sep 11 15:30 train_labels\n",
            "-rw-r--r-- 1 root root      929 Sep 11 15:32 test_labels.csv\n",
            "-rw-r--r-- 1 root root    32735 Sep 11 15:32 train_labels.csv\n",
            "-rw-r--r-- 1 root root     5092 Sep 11 15:32 label_map.pbtxt\n",
            "-rw-r--r-- 1 root root  2006675 Sep 11 15:33 test_labels.record\n",
            "-rw-r--r-- 1 root root 66329466 Sep 11 15:33 train_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMckMSJqFMyc",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the Base Model\n",
        "1. Based on the model selecting at the top of this notebook, downloading the model selected and extracting its content.\n",
        "2. Creating a dir to save the model while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvN9Cw65FQzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcac2928-da97-42c1-92e7-78765d9f26e5"
      },
      "source": [
        "%cd /content/gun_detection/models/research\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "#selecting the model\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "#creating the downlaod link for the model selected\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "#the distination folder where the model will be saved\n",
        "fine_tune_dir = '/content/gun_detection/models/research/pretrained_model'\n",
        "\n",
        "#checks if the model has already been downloaded\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "#unzipping the file and extracting its content\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# creating an output file to save the model while training\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(fine_tune_dir)):\n",
        "    shutil.rmtree(fine_tune_dir)\n",
        "os.rename(MODEL, fine_tune_dir)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjXKVMmFk47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ffcd5cd0-dce2-49ad-9d89-145b6ededea5"
      },
      "source": [
        "#checking the content of the pretrained model.\n",
        "# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n",
        "!echo {fine_tune_dir}\n",
        "!ls -alh {fine_tune_dir}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 24 root   root  4.0K Sep 11 15:33 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnjQgJZiGAcA",
        "colab_type": "text"
      },
      "source": [
        "## Configuring the Training Pipeline\n",
        "1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n",
        "2. Adding some Image augmentation.\n",
        "3. Creating a directory to save the model at each checkpoint while training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az14XVo31Ujp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "508d0bc8-4c43-434e-bb81-752b6b12e948"
      },
      "source": [
        "\n",
        "#the path to the folder containing all the sample config files\n",
        "CONFIG_BASE = \"/content/gun_detection/models/research/object_detection/samples/configs/\"\n",
        "\n",
        "#path to the specified model's config file\n",
        "model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n",
        "model_pipline"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT3m6pbXpN_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the sample config file that is provided by the tf model\n",
        "#!cat /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfsl5CsDGY3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edc93b0f-563b-480e-c92d-e8355a61092e"
      },
      "source": [
        "#editing the configuration file to add the path for the TFRecords files, pbtxt,batch_size,num_steps,num_classes.\n",
        "# any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) would be editted here\n",
        "\n",
        "%%writefile {model_pipline}\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 50 # number of classes to be detected\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    # all images will be resized to the below W x H.\n",
        "    image_resizer { \n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        #use_dropout: false\n",
        "        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "            # weight: 0.00004\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            # weight: 0.00004\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000 \n",
        "        iou_threshold: 0.95\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        \n",
        "        #adjust this to the max number of objects per class. \n",
        "        # ex, in my case, i have one pistol in most of the images.\n",
        "        # . there are some images with more than one up to 16.\n",
        "        max_detections_per_class: 16\n",
        "        # max number of detections among all classes. I have 1 class only so\n",
        "        max_total_detections: 16\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 16 # training batch size\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.003\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "\n",
        "  #the path to the pretrained model. \n",
        "  fine_tune_checkpoint: \"/content/gun_detection/models/research/pretrained_model/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 10000 \n",
        "  \n",
        "\n",
        "  #data augmentaion is done here, you can remove or add more.\n",
        "  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n",
        "  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n",
        "  \n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_adjust_contrast {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    #path to the training TFRecord\n",
        "    input_path: \"/content/gun_detection/data/train_labels.record\"\n",
        "  }\n",
        "  #path to the label map \n",
        "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n",
        "  num_examples: 3\n",
        "  # the number of images to disply in Tensorboard while training\n",
        "  num_visualizations: 3\n",
        "\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  #max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "      \n",
        "    #path to the testing TFRecord\n",
        "    input_path: \"/content/gun_detection/data/test_labels.record\"\n",
        "  }\n",
        "  #path to the label map \n",
        "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXXZLVEG8sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where the model will be saved at each checkpoint while training \n",
        "model_dir = 'training/'\n",
        "\n",
        "# Optionally: remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vAGvftxHu8K",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard\n",
        "1. Downlaoding and unzipping Tensorboard\n",
        "2. creating a link to visualize multiple graph while training.\n",
        "\n",
        "\n",
        "notes: \n",
        "  1. Tensorboard will not log any files until the training starts. \n",
        "  2. a max of 20 connection per minute is allowed when using ngrok, you will not be able to access tensorboard while the model is logging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ucxlc5HxHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "652296a5-1ac5-475b-c5b4-0d19162f0ab1"
      },
      "source": [
        "#downlaoding ngrok to be able to access tensorboard on google colab\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-11 15:33:51--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.194.108.77, 3.215.242.209, 54.236.206.131, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.194.108.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  13.4MB/s    in 1.0s    \n",
            "\n",
            "2020-09-11 15:33:53 (13.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9ufxr7IAdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idsi9zyNIIsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68fe7a27-fc19-4f67-911c-f97528dcbcec"
      },
      "source": [
        "#The link to tensorboard.\n",
        "#works after the training starts.\n",
        "\n",
        "### note: if you didnt get a link as output, rerun this cell and the one above\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://3fc9fb9a0bb1.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuJcAPZFIfu7",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "Finally training the model!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnKt6g0_IgOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1a152fa-0cf6-4715-8ee4-8c20372d3c29"
      },
      "source": [
        "\n",
        "!python3 /content/gun_detection/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={model_pipline}\\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0911 15:34:10.056290 140477469624192 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0911 15:34:10.056516 140477469624192 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0911 15:34:10.056645 140477469624192 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0911 15:34:10.056799 140477469624192 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0911 15:34:10.056935 140477469624192 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0911 15:34:10.057097 140477469624192 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0911 15:34:10.057381 140477469624192 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc30a14e2e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0911 15:34:10.057980 140477469624192 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc30a14e2e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc30a147b70>) includes params argument, but params are not passed to Estimator.\n",
            "W0911 15:34:10.058253 140477469624192 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fc30a147b70>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0911 15:34:10.059174 140477469624192 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0911 15:34:10.059413 140477469624192 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0911 15:34:10.059748 140477469624192 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0911 15:34:10.072086 140477469624192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0911 15:34:10.130776 140477469624192 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0911 15:34:10.136940 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0911 15:34:10.162387 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc30a14ee10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0911 15:34:10.201772 140477469624192 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc30a14ee10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fc3297a6d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0911 15:34:10.456196 140477469624192 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fc3297a6d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0911 15:34:10.463742 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0911 15:34:10.472960 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0911 15:34:10.607563 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0911 15:34:11.663638 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0911 15:34:12.248331 140477469624192 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0911 15:34:12.570068 140477469624192 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:34:15.755687 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:34:15.949464 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:34:15.996377 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:34:16.043433 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:34:16.093538 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:34:16.140119 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0911 15:34:22.171622 140477469624192 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0911 15:34:29.935124 140477469624192 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0911 15:34:29.936821 140477469624192 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0911 15:34:34.208304 140477469624192 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-11 15:34:34.226066: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-09-11 15:34:34.226376: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2405d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-11 15:34:34.226415: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-09-11 15:34:34.234632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-09-11 15:34:34.375597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:34:34.376493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2404f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-11 15:34:34.376527: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-09-11 15:34:34.378007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:34:34.378741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-11 15:34:34.379125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-11 15:34:34.643000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-11 15:34:34.799800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-11 15:34:34.832119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-11 15:34:35.106028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-11 15:34:35.130868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-11 15:34:35.674411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-11 15:34:35.674753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:34:35.675702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:34:35.676442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-11 15:34:35.681259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-11 15:34:35.683071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-11 15:34:35.683106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-11 15:34:35.683124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-11 15:34:35.684409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:34:35.685268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:34:35.685979: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-09-11 15:34:35.686033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0911 15:34:46.270100 140477469624192 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0911 15:34:46.670285 140477469624192 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0911 15:34:58.375748 140477469624192 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-09-11 15:35:17.256979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-11 15:35:21.541005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 183.92407, step = 0\n",
            "I0911 15:35:25.211809 140477469624192 basic_session_run_hooks.py:262] loss = 183.92407, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.00778\n",
            "I0911 15:37:04.439018 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 1.00778\n",
            "INFO:tensorflow:loss = 16.620253, step = 100 (99.229 sec)\n",
            "I0911 15:37:04.440503 140477469624192 basic_session_run_hooks.py:260] loss = 16.620253, step = 100 (99.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.08656\n",
            "I0911 15:38:36.472147 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 1.08656\n",
            "INFO:tensorflow:loss = 12.889014, step = 200 (92.033 sec)\n",
            "I0911 15:38:36.473294 140477469624192 basic_session_run_hooks.py:260] loss = 12.889014, step = 200 (92.033 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.07166\n",
            "I0911 15:40:09.785152 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 1.07166\n",
            "INFO:tensorflow:loss = 12.40187, step = 300 (93.313 sec)\n",
            "I0911 15:40:09.786551 140477469624192 basic_session_run_hooks.py:260] loss = 12.40187, step = 300 (93.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.06846\n",
            "I0911 15:41:43.377466 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 1.06846\n",
            "INFO:tensorflow:loss = 11.607925, step = 400 (93.592 sec)\n",
            "I0911 15:41:43.378759 140477469624192 basic_session_run_hooks.py:260] loss = 11.607925, step = 400 (93.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.06592\n",
            "I0911 15:43:17.193222 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 1.06592\n",
            "INFO:tensorflow:loss = 10.354418, step = 500 (93.816 sec)\n",
            "I0911 15:43:17.194753 140477469624192 basic_session_run_hooks.py:260] loss = 10.354418, step = 500 (93.816 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.07292\n",
            "I0911 15:44:50.396409 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 1.07292\n",
            "INFO:tensorflow:loss = 10.013843, step = 600 (93.203 sec)\n",
            "I0911 15:44:50.397596 140477469624192 basic_session_run_hooks.py:260] loss = 10.013843, step = 600 (93.203 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 613 into training/model.ckpt.\n",
            "I0911 15:45:01.693963 140477469624192 basic_session_run_hooks.py:606] Saving checkpoints for 613 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc2f11d5978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0911 15:45:03.459196 140477469624192 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fc2f11d5978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc302db2ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0911 15:45:03.679753 140477469624192 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fc302db2ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0911 15:45:04.327364 140477469624192 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:45:07.061970 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:45:07.103147 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:45:07.142892 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:45:07.183916 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:45:07.229765 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0911 15:45:07.270032 140477469624192 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/eval_util.py:879: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0911 15:45:10.503038 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/eval_util.py:879: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0911 15:45:10.759802 140477469624192 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0911 15:45:11.360984 140477469624192 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-09-11T15:45:11Z\n",
            "I0911 15:45:11.381877 140477469624192 evaluation.py:255] Starting evaluation at 2020-09-11T15:45:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0911 15:45:11.908278 140477469624192 monitored_session.py:240] Graph was finalized.\n",
            "2020-09-11 15:45:11.909906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:45:11.910664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-11 15:45:11.910805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-11 15:45:11.910857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-11 15:45:11.910899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-11 15:45:11.910947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-11 15:45:11.910994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-11 15:45:11.911044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-11 15:45:11.911088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-11 15:45:11.911238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:45:11.911904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:45:11.912434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-09-11 15:45:11.912542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-11 15:45:11.912568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-09-11 15:45:11.912584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-09-11 15:45:11.912806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:45:11.913471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-11 15:45:11.914067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-613\n",
            "I0911 15:45:11.915287 140477469624192 saver.py:1284] Restoring parameters from training/model.ckpt-613\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0911 15:45:13.100172 140477469624192 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0911 15:45:13.277382 140477469624192 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 3 images.\n",
            "I0911 15:45:16.886287 140475270829824 coco_evaluation.py:282] Performing evaluation on 3 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0911 15:45:16.886920 140475270829824 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0911 15:45:16.887765 140475270829824 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-09-11-15:45:17\n",
            "I0911 15:45:17.282133 140477469624192 evaluation.py:275] Finished evaluation at 2020-09-11-15:45:17\n",
            "INFO:tensorflow:Saving dict for global step 613: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 53.67137, Loss/localization_loss = 2.970153, Loss/regularization_loss = 1.6035261, Loss/total_loss = 58.245045, global_step = 613, learning_rate = 0.003, loss = 58.245045\n",
            "I0911 15:45:17.282448 140477469624192 estimator.py:2049] Saving dict for global step 613: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 53.67137, Loss/localization_loss = 2.970153, Loss/regularization_loss = 1.6035261, Loss/total_loss = 58.245045, global_step = 613, learning_rate = 0.003, loss = 58.245045\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 613: training/model.ckpt-613\n",
            "I0911 15:45:18.474599 140477469624192 estimator.py:2109] Saving 'checkpoint_path' summary for global step 613: training/model.ckpt-613\n",
            "INFO:tensorflow:global_step/sec: 0.897942\n",
            "I0911 15:46:41.762205 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 0.897942\n",
            "INFO:tensorflow:loss = 10.43013, step = 700 (111.366 sec)\n",
            "I0911 15:46:41.763470 140477469624192 basic_session_run_hooks.py:260] loss = 10.43013, step = 700 (111.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.08421\n",
            "I0911 15:48:13.995041 140477469624192 basic_session_run_hooks.py:692] global_step/sec: 1.08421\n",
            "INFO:tensorflow:loss = 9.259363, step = 800 (92.233 sec)\n",
            "I0911 15:48:13.996286 140477469624192 basic_session_run_hooks.py:260] loss = 9.259363, step = 800 (92.233 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPN8liiQc7Ue",
        "colab_type": "text"
      },
      "source": [
        "## Exporting The Trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upwUdom0lTub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#the location where the exported model will be saved in.\n",
        "output_directory = '/content/gun_detection/models/research/fine_tuned_model'\n",
        "\n",
        "# goes through the model is the training/ dir and gets the last one.\n",
        "# you could choose a specfic one instead of the last\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "#exports the model specifed and inference graph\n",
        "!python /content/gun_detection/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={model_pipline} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuxDnGPM_JPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downloads the frozen model that is needed for inference\n",
        "files.download(output_directory + '/frozen_inference_graph.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTkkaGq5BpYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downlaod the label map\n",
        "files.download(DATA_BASE_PATH + '/label_map.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWr3WwzHL2vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}